{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4be3fe",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "Develo a ranked retrieval system which takes free text queries from the user, ranks the documents according to the relevance and returns five most relevant documents (i.e., IDs of the top 5 documents)\n",
    "\n",
    "### Dataset\n",
    "Subset of Cranfield collection, published in 1960s. It consists of 5 files.\n",
    "\n",
    "- Documents.csv- 387 aerodynamics journal articles' abstracts\n",
    "- queries.csv- 85 free text queries for training\n",
    "- qrel.csv- contains 5 relevant documents for every query in training set.\n",
    "- queries_val.csv- 22 free text queries for validation\n",
    "- qrel_val.csv- Contains 5 relevant documents for every query in validation set.\n",
    "\n",
    "\n",
    "\n",
    "### Steps to build a ranked retrieval system\n",
    "\n",
    "- Load the dataset\n",
    "- Text pre-processing\n",
    "- Ranking documents and evaluation using MAP\n",
    "- We will use the following\n",
    "    - Jaccard Coefficient\n",
    "    - Term Frequency\n",
    "    - Inverse Document Frequency\n",
    "    - TF-IDF\n",
    "    - TF-IDF based Vector space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c3c6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "#loading model\n",
    "nlp= spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1957aca3",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5587ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (387, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>author</th>\n",
       "      <th>bibliography</th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ting-yili</td>\n",
       "      <td>department of aeronautical engineering, rensse...</td>\n",
       "      <td>simple shear flow past a flat plate in an inco...</td>\n",
       "      <td>simple shear flow past a flat plate in an inco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>m. b. glauert</td>\n",
       "      <td>department of mathematics, university of manch...</td>\n",
       "      <td>the boundary layer in simple shear flow past a...</td>\n",
       "      <td>the boundary layer in simple shear flow past a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>wasserman,b.</td>\n",
       "      <td>j. ae. scs. 24, 1957, 924.</td>\n",
       "      <td>one-dimensional transient heat conduction into...</td>\n",
       "      <td>one-dimensional transient heat conduction into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>campbell,w.f.</td>\n",
       "      <td>j. ae. scs. 25, 1958, 340.</td>\n",
       "      <td>one-dimensional transient heat flow in a multi...</td>\n",
       "      <td>one-dimensional transient heat flow in a multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>bisplinghoff,r.l.</td>\n",
       "      <td>j. ae. scs. 23, 1956, 289.</td>\n",
       "      <td>some structural and aerelastic considerations ...</td>\n",
       "      <td>some structural and aerelastic considerations ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid             author  \\\n",
       "0      2          ting-yili   \n",
       "1      3      m. b. glauert   \n",
       "2      5       wasserman,b.   \n",
       "3      6      campbell,w.f.   \n",
       "4     12  bisplinghoff,r.l.   \n",
       "\n",
       "                                        bibliography  \\\n",
       "0  department of aeronautical engineering, rensse...   \n",
       "1  department of mathematics, university of manch...   \n",
       "2                         j. ae. scs. 24, 1957, 924.   \n",
       "3                         j. ae. scs. 25, 1958, 340.   \n",
       "4                         j. ae. scs. 23, 1956, 289.   \n",
       "\n",
       "                                                body  \\\n",
       "0  simple shear flow past a flat plate in an inco...   \n",
       "1  the boundary layer in simple shear flow past a...   \n",
       "2  one-dimensional transient heat conduction into...   \n",
       "3  one-dimensional transient heat flow in a multi...   \n",
       "4  some structural and aerelastic considerations ...   \n",
       "\n",
       "                                               title  \n",
       "0  simple shear flow past a flat plate in an inco...  \n",
       "1  the boundary layer in simple shear flow past a...  \n",
       "2  one-dimensional transient heat conduction into...  \n",
       "3  one-dimensional transient heat flow in a multi...  \n",
       "4  some structural and aerelastic considerations ...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Documents\n",
    "documents= pd.read_csv('dataset/documents.csv')\n",
    "print(\"Shape :\", documents.shape)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5c7cc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (85, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query\n",
       "0    1  what similarity laws must be obeyed when const...\n",
       "1    2  what are the structural and aeroelastic proble...\n",
       "2    3  what problems of heat conduction in composite ...\n",
       "3    8  what methods -dash exact or approximate -dash ...\n",
       "4   10  are real-gas transport properties for air avai..."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Queries- Queries with query ID\n",
    "queries= pd.read_csv('dataset/queries.csv')\n",
    "print(\"Shape :\", queries.shape)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0aa876e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (425, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid  docid\n",
       "0    1    184\n",
       "1    1     29\n",
       "2    1     31\n",
       "3    1     57\n",
       "4    1    378"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Qrel- gives relevant document list\n",
    "qrel= pd.read_csv('dataset/qrel.csv')\n",
    "print(\"Shape :\", qrel.shape)\n",
    "qrel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "710352e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (22, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>is there a design method for calculating therm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>will an analysis of panel flutter based on arb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>what is the criterion for true panel flutter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>how can the analytical solution of the bucklin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>the problem of similarity for representative i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query\n",
       "0  189  is there a design method for calculating therm...\n",
       "1  190  will an analysis of panel flutter based on arb...\n",
       "2  191  what is the criterion for true panel flutter, ...\n",
       "3  194  how can the analytical solution of the bucklin...\n",
       "4  196  the problem of similarity for representative i..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#queries_val: Validation queries\n",
    "\n",
    "queries_val= pd.read_csv('dataset/queries_val.csv')\n",
    "print(\"Shape :\", queries_val.shape)\n",
    "queries_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2aa8c6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (110, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid  docid\n",
       "0  189    395\n",
       "1  189    866\n",
       "2  189    869\n",
       "3  189    865\n",
       "4  189    868"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qrel_val: List of relevant docs for validation queries\n",
    "\n",
    "qrel_val= pd.read_csv('dataset/qrel_val.csv')\n",
    "print(\"Shape :\", qrel_val.shape)\n",
    "qrel_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787759c",
   "metadata": {},
   "source": [
    "### Loading sample queries and documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fb036ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['what progress has been made in research on unsteady aerodynamics .',\n",
       "       'how far around a cylinder and under what conditions of flow, if any, is the velocity just outside of the boundary layer a linear function of the distance around the cylinder .',\n",
       "       'can series expansions be found for the boundary layer on a flat plate in a shear flow .',\n",
       "       'what is the combined effect of surface heat and mass transfer on hypersonic flow .',\n",
       "       'does a practical flow follow the theoretical concepts for the interaction between adjacent blade rows of a supersonic cascade .',\n",
       "       'why do users of orthodox pitot-static tubes often find that the calibrations appear to be,. - (a) significantly different from those formerly specified,  (b) wildly variable at low reynolds numbers .',\n",
       "       'are previous analyses of circumferential thermal buckling of circular cylindrical shells unnecessarily involved or even inaccurate due to the assumed forms of buckling mode .',\n",
       "       'are there any theoretical methods for predicting base pressure .',\n",
       "       'are there experimental results on the stability of a compressible boundary layer induced by a moving wave .',\n",
       "       'how can wing-body, flow field interference effects be approximated rationally .'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading sample queries\n",
    "queries['query'].sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "53c028f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"simple shear flow past a flat plate in an incompressible fluid of small viscosity . in the study of high-speed viscous flow past a two-dimensional body it is usually necessary to consider a curved shock wave emitting from the nose or leading edge of the body .  consequently, there exists an inviscid rotational flow region between the shock wave and the boundary layer .  such a situation arises, for instance, in the study of the hypersonic viscous flow past a flat plate .  the situation is somewhat different from prandtl's classical boundary-layer problem . in prandtl's original problem the inviscid free stream outside the boundary layer is irrotational while in a hypersonic boundary-layer problem the inviscid free stream must be considered as rotational .  the possible effects of vorticity have been recently discussed by ferri and libby .  in the present paper, the simple shear flow past a flat plate in a fluid of small viscosity is investigated .  it can be shown that this problem can again be treated by the boundary-layer approximation, the only novel feature being that the free stream has a constant vorticity .  the discussion here is restricted to two-dimensional incompressible steady flow .\",\n",
       "       'the boundary layer in simple shear flow past a flat plate . the boundary-layer equations are presented for steady incompressible flow with no pressure gradient .',\n",
       "       'one-dimensional transient heat conduction into a double-layer slab subjected to a linear heat input for a small time internal .   analytic solutions are presented for the transient heat conduction in composite slabs exposed at one surface to a triangular heat rate .  this type of heating rate may occur, for example, during aerodynamic heating .',\n",
       "       \"one-dimensional transient heat flow in a multilayer slab .   in a recent contribution to the readers' forum wassermann gave analytic solutions for the temperature in a double layer slab, with a triangular heat rate input at one face, insulated at the other, and with no thermal resistance at the interface .  his solutions were for the three particular cases.. i propose here to give the general solution to this problem, to indicate briefly how it is obtained using the method of reference 2, and to point out that the solutions given by wassermann are incomplete for times longer than the duration of the heat input .\",\n",
       "       'some structural and aerelastic considerations of high speed flight .   the dominating factors in structural design of high-speed aircraft are thermal and aeroelastic in origin .  the subject matter is concerned largely with a discussion of these factors and their interrelation with one another .  a summary is presented of some of the analytical and experimental tools available to aeronautical engineers to meet the demands of high-speed flight upon aircraft structures .  the state of the art with respect to heat transfer from the boundary layer into the structure, modes of failure under combined load as well as thermal inputs and acrothermoelasticity is discussed .  methods of attacking and alleviating structural and aeroelastic problems of high-speed flight are summarized .  finally, some avenues of fundamental research are suggested .'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading sample documents\n",
    "\n",
    "documents['body'][:5].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c3a32",
   "metadata": {},
   "source": [
    "### Text pre-processing\n",
    "\n",
    "The text appears to be all in lower case. But there are still some hyphens, extra spaces etc., which we can remove through regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "112d7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    #split on hyphen and replace with blank spaces\n",
    "    text= re.sub(\"-\",\" \", text)\n",
    "    \n",
    "    #keep only the words\n",
    "    text= re.sub(\"[^a-z ]+\", \"\", text)\n",
    "    \n",
    "    #removing extra spaces\n",
    "    text= re.sub(\"[\\s]+\", \" \", text)\n",
    "    \n",
    "    #creating doc object\n",
    "    doc= nlp(text)\n",
    "    \n",
    "    # remove stopwords and lemmatize the text\n",
    "    tokens= [token.lemma_ for token in doc if(token.is_stop==False)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a726a7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>author</th>\n",
       "      <th>bibliography</th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ting-yili</td>\n",
       "      <td>department of aeronautical engineering, rensse...</td>\n",
       "      <td>simple shear flow past a flat plate in an inco...</td>\n",
       "      <td>simple shear flow past a flat plate in an inco...</td>\n",
       "      <td>[simple, shear, flow, past, flat, plate, incom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>m. b. glauert</td>\n",
       "      <td>department of mathematics, university of manch...</td>\n",
       "      <td>the boundary layer in simple shear flow past a...</td>\n",
       "      <td>the boundary layer in simple shear flow past a...</td>\n",
       "      <td>[boundary, layer, simple, shear, flow, past, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>wasserman,b.</td>\n",
       "      <td>j. ae. scs. 24, 1957, 924.</td>\n",
       "      <td>one-dimensional transient heat conduction into...</td>\n",
       "      <td>one-dimensional transient heat conduction into...</td>\n",
       "      <td>[dimensional, transient, heat, conduction, dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>campbell,w.f.</td>\n",
       "      <td>j. ae. scs. 25, 1958, 340.</td>\n",
       "      <td>one-dimensional transient heat flow in a multi...</td>\n",
       "      <td>one-dimensional transient heat flow in a multi...</td>\n",
       "      <td>[dimensional, transient, heat, flow, multilaye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>bisplinghoff,r.l.</td>\n",
       "      <td>j. ae. scs. 23, 1956, 289.</td>\n",
       "      <td>some structural and aerelastic considerations ...</td>\n",
       "      <td>some structural and aerelastic considerations ...</td>\n",
       "      <td>[structural, aerelastic, consideration, high, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid             author  \\\n",
       "0      2          ting-yili   \n",
       "1      3      m. b. glauert   \n",
       "2      5       wasserman,b.   \n",
       "3      6      campbell,w.f.   \n",
       "4     12  bisplinghoff,r.l.   \n",
       "\n",
       "                                        bibliography  \\\n",
       "0  department of aeronautical engineering, rensse...   \n",
       "1  department of mathematics, university of manch...   \n",
       "2                         j. ae. scs. 24, 1957, 924.   \n",
       "3                         j. ae. scs. 25, 1958, 340.   \n",
       "4                         j. ae. scs. 23, 1956, 289.   \n",
       "\n",
       "                                                body  \\\n",
       "0  simple shear flow past a flat plate in an inco...   \n",
       "1  the boundary layer in simple shear flow past a...   \n",
       "2  one-dimensional transient heat conduction into...   \n",
       "3  one-dimensional transient heat flow in a multi...   \n",
       "4  some structural and aerelastic considerations ...   \n",
       "\n",
       "                                               title  \\\n",
       "0  simple shear flow past a flat plate in an inco...   \n",
       "1  the boundary layer in simple shear flow past a...   \n",
       "2  one-dimensional transient heat conduction into...   \n",
       "3  one-dimensional transient heat flow in a multi...   \n",
       "4  some structural and aerelastic considerations ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [simple, shear, flow, past, flat, plate, incom...  \n",
       "1  [boundary, layer, simple, shear, flow, past, f...  \n",
       "2  [dimensional, transient, heat, conduction, dou...  \n",
       "3  [dimensional, transient, heat, flow, multilaye...  \n",
       "4  [structural, aerelastic, consideration, high, ...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing on documents\n",
    "documents['tokens']= documents['body'].apply(preprocess)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1341a847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "      <td>[similarity, law, obey, construct, aeroelastic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "      <td>[structural, aeroelastic, problem, associate, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "      <td>[problem, heat, conduction, composite, slab, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "      <td>[method, dash, exact, approximate, dash, prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "      <td>[real, gas, transport, property, air, availabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0    1  what similarity laws must be obeyed when const...   \n",
       "1    2  what are the structural and aeroelastic proble...   \n",
       "2    3  what problems of heat conduction in composite ...   \n",
       "3    8  what methods -dash exact or approximate -dash ...   \n",
       "4   10  are real-gas transport properties for air avai...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [similarity, law, obey, construct, aeroelastic...  \n",
       "1  [structural, aeroelastic, problem, associate, ...  \n",
       "2  [problem, heat, conduction, composite, slab, s...  \n",
       "3  [method, dash, exact, approximate, dash, prese...  \n",
       "4  [real, gas, transport, property, air, availabl...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing on queries\n",
    "queries['tokens']= queries['query'].apply(preprocess)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cf1d69a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>is there a design method for calculating therm...</td>\n",
       "      <td>[design, method, calculate, thermal, fatigue, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>will an analysis of panel flutter based on arb...</td>\n",
       "      <td>[analysis, panel, flutter, base, arbitrarily, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>what is the criterion for true panel flutter, ...</td>\n",
       "      <td>[criterion, true, panel, flutter, oppose, smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>how can the analytical solution of the bucklin...</td>\n",
       "      <td>[analytical, solution, buckle, strength, unifo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>the problem of similarity for representative i...</td>\n",
       "      <td>[problem, similarity, representative, investig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0  189  is there a design method for calculating therm...   \n",
       "1  190  will an analysis of panel flutter based on arb...   \n",
       "2  191  what is the criterion for true panel flutter, ...   \n",
       "3  194  how can the analytical solution of the bucklin...   \n",
       "4  196  the problem of similarity for representative i...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [design, method, calculate, thermal, fatigue, ...  \n",
       "1  [analysis, panel, flutter, base, arbitrarily, ...  \n",
       "2  [criterion, true, panel, flutter, oppose, smal...  \n",
       "3  [analytical, solution, buckle, strength, unifo...  \n",
       "4  [problem, similarity, representative, investig...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre-processing on queries for validation\n",
    "queries_val['tokens']= queries_val['query'].apply(preprocess)\n",
    "queries_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a890ec",
   "metadata": {},
   "source": [
    "### Ranking documents and evaluation using MAP\n",
    "\n",
    "#### Jaccard Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c23fcbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a temporary dataframe\n",
    "\n",
    "temp_doc= documents[['docid', 'tokens']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "812ca40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coefficient(dtokens, qtokens):\n",
    "    #calculating A intersection B\n",
    "    numerator= len(set(dtokens).intersection(set(qtokens)))\n",
    "    #calculating A union B\n",
    "    denominator= len(set(dtokens).union(set(qtokens)))\n",
    "    \n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0a1387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02702702702702703"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the jaccard coefficient for a sample query-document pair\n",
    "\n",
    "jaccard_coefficient(temp_doc['tokens'][0], queries['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0a9042c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[simple, shear, flow, past, flat, plate, incom...</td>\n",
       "      <td>0.027027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[boundary, layer, simple, shear, flow, past, f...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[dimensional, transient, heat, conduction, dou...</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[dimensional, transient, heat, flow, multilaye...</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>[structural, aerelastic, consideration, high, ...</td>\n",
       "      <td>0.084746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>[dimensional, panel, flutter, theory, experime...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>[transformation, compressible, turbulent, boun...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>[heat, transfer, slip, flow, number, author, c...</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>[skin, friction, heat, transfer, characteristi...</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>[theory, stagnation, point, heat, transfer, di...</td>\n",
       "      <td>0.032609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid                                             tokens   jaccard\n",
       "0      2  [simple, shear, flow, past, flat, plate, incom...  0.027027\n",
       "1      3  [boundary, layer, simple, shear, flow, past, f...  0.000000\n",
       "2      5  [dimensional, transient, heat, conduction, dou...  0.028571\n",
       "3      6  [dimensional, transient, heat, flow, multilaye...  0.020408\n",
       "4     12  [structural, aerelastic, consideration, high, ...  0.084746\n",
       "5     15  [dimensional, panel, flutter, theory, experime...  0.000000\n",
       "6     16  [transformation, compressible, turbulent, boun...  0.000000\n",
       "7     21  [heat, transfer, slip, flow, number, author, c...  0.030303\n",
       "8     23  [skin, friction, heat, transfer, characteristi...  0.017857\n",
       "9     24  [theory, stagnation, point, heat, transfer, di...  0.032609"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting Jaccard coefficient for all the documents against a sample query\n",
    "\n",
    "temp_doc['jaccard']= temp_doc['tokens'].apply(lambda x: jaccard_coefficient(x, queries['tokens'][0]))\n",
    "temp_doc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c7971f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>[structural, aerelastic, consideration, high, ...</td>\n",
       "      <td>0.084746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>[theory, aircraft, structural, model, subject,...</td>\n",
       "      <td>0.084746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>378</td>\n",
       "      <td>[engineering, relation, friction, heat, transf...</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670</td>\n",
       "      <td>[blunt, body, heat, transfer, hypersonic, spee...</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>[model, aeroelastic, investigation, addendum, ...</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>184</td>\n",
       "      <td>[scale, model, thermo, aeroelastic, research, ...</td>\n",
       "      <td>0.057971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1111</td>\n",
       "      <td>[research, high, speed, flutter, paper, presen...</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>436</td>\n",
       "      <td>[heat, transfer, planetary, atmosphere, super,...</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>629</td>\n",
       "      <td>[second, order, effect, laminar, boundary, lay...</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1305</td>\n",
       "      <td>[propose, programme, wind, tunnel, test, hyper...</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid                                             tokens   jaccard\n",
       "0     12  [structural, aerelastic, consideration, high, ...  0.084746\n",
       "1     51  [theory, aircraft, structural, model, subject,...  0.084746\n",
       "2    378  [engineering, relation, friction, heat, transf...  0.073171\n",
       "3    670  [blunt, body, heat, transfer, hypersonic, spee...  0.066667\n",
       "4    875  [model, aeroelastic, investigation, addendum, ...  0.066667\n",
       "5    184  [scale, model, thermo, aeroelastic, research, ...  0.057971\n",
       "6   1111  [research, high, speed, flutter, paper, presen...  0.057143\n",
       "7    436  [heat, transfer, planetary, atmosphere, super,...  0.055556\n",
       "8    629  [second, order, effect, laminar, boundary, lay...  0.055556\n",
       "9   1305  [propose, programme, wind, tunnel, test, hyper...  0.055556"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DocIDs of the top 10 most relevant documents\n",
    "temp_doc.sort_values(by='jaccard', ascending= False).head(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8124a4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12,  51, 378, 670, 875])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DocID of top 5 most relevant documents\n",
    "temp_doc.sort_values(by='jaccard', ascending=False).head()['docid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ab994979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding jaccard_coefficient\n",
    "def jaccard_rank(qtokens):\n",
    "  # Find jaccard coefficient for all docs\n",
    "  temp_doc['jaccard']=temp_doc['tokens'].apply(lambda x: jaccard_coefficient(x,qtokens))\n",
    "\n",
    "  # Find top 5 most relevant docs\n",
    "  relevant_docids=temp_doc.sort_values(by='jaccard',ascending=False).head()['docid'].values\n",
    "  return relevant_docids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e19651f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "      <td>[similarity, law, obey, construct, aeroelastic...</td>\n",
       "      <td>[12, 51, 378, 670, 875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "      <td>[structural, aeroelastic, problem, associate, ...</td>\n",
       "      <td>[12, 51, 700, 746, 875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "      <td>[problem, heat, conduction, composite, slab, s...</td>\n",
       "      <td>[5, 584, 6, 145, 582]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "      <td>[method, dash, exact, approximate, dash, prese...</td>\n",
       "      <td>[122, 1306, 639, 655, 988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "      <td>[real, gas, transport, property, air, availabl...</td>\n",
       "      <td>[405, 302, 436, 583, 616]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0    1  what similarity laws must be obeyed when const...   \n",
       "1    2  what are the structural and aeroelastic proble...   \n",
       "2    3  what problems of heat conduction in composite ...   \n",
       "3    8  what methods -dash exact or approximate -dash ...   \n",
       "4   10  are real-gas transport properties for air avai...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [similarity, law, obey, construct, aeroelastic...   \n",
       "1  [structural, aeroelastic, problem, associate, ...   \n",
       "2  [problem, heat, conduction, composite, slab, s...   \n",
       "3  [method, dash, exact, approximate, dash, prese...   \n",
       "4  [real, gas, transport, property, air, availabl...   \n",
       "\n",
       "                  jaccard_rel  \n",
       "0     [12, 51, 378, 670, 875]  \n",
       "1     [12, 51, 700, 746, 875]  \n",
       "2       [5, 584, 6, 145, 582]  \n",
       "3  [122, 1306, 639, 655, 988]  \n",
       "4   [405, 302, 436, 583, 616]  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ranking documents according to jaccard coefficient\n",
    "queries['jaccard_rel']= queries['tokens'].apply(lambda x: jaccard_rank(x))\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3410f819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard_rel</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "      <td>[similarity, law, obey, construct, aeroelastic...</td>\n",
       "      <td>[12, 51, 378, 670, 875]</td>\n",
       "      <td>[184, 29, 31, 57, 378]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "      <td>[structural, aeroelastic, problem, associate, ...</td>\n",
       "      <td>[12, 51, 700, 746, 875]</td>\n",
       "      <td>[12, 746, 15, 184, 858]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "      <td>[problem, heat, conduction, composite, slab, s...</td>\n",
       "      <td>[5, 584, 6, 145, 582]</td>\n",
       "      <td>[5, 6, 90, 91, 119]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "      <td>[method, dash, exact, approximate, dash, prese...</td>\n",
       "      <td>[122, 1306, 639, 655, 988]</td>\n",
       "      <td>[48, 122, 354, 360, 1005]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "      <td>[real, gas, transport, property, air, availabl...</td>\n",
       "      <td>[405, 302, 436, 583, 616]</td>\n",
       "      <td>[259, 405, 302, 436, 437]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0    1  what similarity laws must be obeyed when const...   \n",
       "1    2  what are the structural and aeroelastic proble...   \n",
       "2    3  what problems of heat conduction in composite ...   \n",
       "3    8  what methods -dash exact or approximate -dash ...   \n",
       "4   10  are real-gas transport properties for air avai...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [similarity, law, obey, construct, aeroelastic...   \n",
       "1  [structural, aeroelastic, problem, associate, ...   \n",
       "2  [problem, heat, conduction, composite, slab, s...   \n",
       "3  [method, dash, exact, approximate, dash, prese...   \n",
       "4  [real, gas, transport, property, air, availabl...   \n",
       "\n",
       "                  jaccard_rel               ground_truth  \n",
       "0     [12, 51, 378, 670, 875]     [184, 29, 31, 57, 378]  \n",
       "1     [12, 51, 700, 746, 875]    [12, 746, 15, 184, 858]  \n",
       "2       [5, 584, 6, 145, 582]        [5, 6, 90, 91, 119]  \n",
       "3  [122, 1306, 639, 655, 988]  [48, 122, 354, 360, 1005]  \n",
       "4   [405, 302, 436, 583, 616]  [259, 405, 302, 436, 437]  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding ground truth in a column\n",
    "queries['ground_truth']= queries['qid'].apply(lambda x:qrel[qrel['qid']==x]['docid'].values)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c83ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(model_rel, ground_truth):\n",
    "    tp= 0\n",
    "    precisions= []\n",
    "    \n",
    "    #finding precision at points at which relevant document is returned\n",
    "    for index, value in enumerate(model_rel):\n",
    "        if value in ground_truth:\n",
    "            tp+=1\n",
    "            precisions.append(tp/(index+1))\n",
    "            \n",
    "    #id no relevant document in list then return 0\n",
    "    if precisions== []:\n",
    "        return 0\n",
    "    \n",
    "    return np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a61a78e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041666666666667"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's run the above on a sample\n",
    "average_precision([5,6,1,2,3], [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1902cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard_rel</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>jaccard_ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "      <td>[similarity, law, obey, construct, aeroelastic...</td>\n",
       "      <td>[12, 51, 378, 670, 875]</td>\n",
       "      <td>[184, 29, 31, 57, 378]</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "      <td>[structural, aeroelastic, problem, associate, ...</td>\n",
       "      <td>[12, 51, 700, 746, 875]</td>\n",
       "      <td>[12, 746, 15, 184, 858]</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "      <td>[problem, heat, conduction, composite, slab, s...</td>\n",
       "      <td>[5, 584, 6, 145, 582]</td>\n",
       "      <td>[5, 6, 90, 91, 119]</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "      <td>[method, dash, exact, approximate, dash, prese...</td>\n",
       "      <td>[122, 1306, 639, 655, 988]</td>\n",
       "      <td>[48, 122, 354, 360, 1005]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "      <td>[real, gas, transport, property, air, availabl...</td>\n",
       "      <td>[405, 302, 436, 583, 616]</td>\n",
       "      <td>[259, 405, 302, 436, 437]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0    1  what similarity laws must be obeyed when const...   \n",
       "1    2  what are the structural and aeroelastic proble...   \n",
       "2    3  what problems of heat conduction in composite ...   \n",
       "3    8  what methods -dash exact or approximate -dash ...   \n",
       "4   10  are real-gas transport properties for air avai...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [similarity, law, obey, construct, aeroelastic...   \n",
       "1  [structural, aeroelastic, problem, associate, ...   \n",
       "2  [problem, heat, conduction, composite, slab, s...   \n",
       "3  [method, dash, exact, approximate, dash, prese...   \n",
       "4  [real, gas, transport, property, air, availabl...   \n",
       "\n",
       "                  jaccard_rel               ground_truth  jaccard_ap  \n",
       "0     [12, 51, 378, 670, 875]     [184, 29, 31, 57, 378]    0.333333  \n",
       "1     [12, 51, 700, 746, 875]    [12, 746, 15, 184, 858]    0.750000  \n",
       "2       [5, 584, 6, 145, 582]        [5, 6, 90, 91, 119]    0.833333  \n",
       "3  [122, 1306, 639, 655, 988]  [48, 122, 354, 360, 1005]    1.000000  \n",
       "4   [405, 302, 436, 583, 616]  [259, 405, 302, 436, 437]    1.000000  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding average precision for each query\n",
    "queries['jaccard_ap']= queries.apply(lambda x: average_precision(x['jaccard_rel'], x['ground_truth']), axis=1)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "220dc362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision : 0.49555555555555564\n"
     ]
    }
   ],
   "source": [
    "#Mean average precision\n",
    "print('Mean Average Precision :', queries['jaccard_ap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff536e",
   "metadata": {},
   "source": [
    "#### Evaluation on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3bd2c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding ground truth in a column\n",
    "queries_val['ground_truth']= queries_val['qid'].apply(lambda x:qrel_val[qrel_val['qid']==x]['docid'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "45e19bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>jaccard_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>is there a design method for calculating therm...</td>\n",
       "      <td>[design, method, calculate, thermal, fatigue, ...</td>\n",
       "      <td>[395, 866, 869, 865, 868]</td>\n",
       "      <td>[868, 1306, 833, 906, 909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>will an analysis of panel flutter based on arb...</td>\n",
       "      <td>[analysis, panel, flutter, base, arbitrarily, ...</td>\n",
       "      <td>[15, 391, 285, 390, 864]</td>\n",
       "      <td>[390, 1008, 285, 21, 391]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>what is the criterion for true panel flutter, ...</td>\n",
       "      <td>[criterion, true, panel, flutter, oppose, smal...</td>\n",
       "      <td>[914, 915, 285, 857, 858]</td>\n",
       "      <td>[285, 31, 864, 728, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>how can the analytical solution of the bucklin...</td>\n",
       "      <td>[analytical, solution, buckle, strength, unifo...</td>\n",
       "      <td>[739, 740, 742, 743, 744]</td>\n",
       "      <td>[932, 744, 1050, 1172, 1171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>the problem of similarity for representative i...</td>\n",
       "      <td>[problem, similarity, representative, investig...</td>\n",
       "      <td>[51, 185, 874, 875, 876]</td>\n",
       "      <td>[875, 1008, 184, 864, 655]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0  189  is there a design method for calculating therm...   \n",
       "1  190  will an analysis of panel flutter based on arb...   \n",
       "2  191  what is the criterion for true panel flutter, ...   \n",
       "3  194  how can the analytical solution of the bucklin...   \n",
       "4  196  the problem of similarity for representative i...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [design, method, calculate, thermal, fatigue, ...   \n",
       "1  [analysis, panel, flutter, base, arbitrarily, ...   \n",
       "2  [criterion, true, panel, flutter, oppose, smal...   \n",
       "3  [analytical, solution, buckle, strength, unifo...   \n",
       "4  [problem, similarity, representative, investig...   \n",
       "\n",
       "                ground_truth                   jaccard_rel  \n",
       "0  [395, 866, 869, 865, 868]    [868, 1306, 833, 906, 909]  \n",
       "1   [15, 391, 285, 390, 864]     [390, 1008, 285, 21, 391]  \n",
       "2  [914, 915, 285, 857, 858]       [285, 31, 864, 728, 15]  \n",
       "3  [739, 740, 742, 743, 744]  [932, 744, 1050, 1172, 1171]  \n",
       "4   [51, 185, 874, 875, 876]    [875, 1008, 184, 864, 655]  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ranking documents according to jaccard coefficient\n",
    "queries_val['jaccard_rel']= queries_val['tokens'].apply(lambda x: jaccard_rank(x))\n",
    "queries_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ccebe989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>jaccard_rel</th>\n",
       "      <th>jaccard_ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>is there a design method for calculating therm...</td>\n",
       "      <td>[design, method, calculate, thermal, fatigue, ...</td>\n",
       "      <td>[395, 866, 869, 865, 868]</td>\n",
       "      <td>[868, 1306, 833, 906, 909]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>will an analysis of panel flutter based on arb...</td>\n",
       "      <td>[analysis, panel, flutter, base, arbitrarily, ...</td>\n",
       "      <td>[15, 391, 285, 390, 864]</td>\n",
       "      <td>[390, 1008, 285, 21, 391]</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>what is the criterion for true panel flutter, ...</td>\n",
       "      <td>[criterion, true, panel, flutter, oppose, smal...</td>\n",
       "      <td>[914, 915, 285, 857, 858]</td>\n",
       "      <td>[285, 31, 864, 728, 15]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>how can the analytical solution of the bucklin...</td>\n",
       "      <td>[analytical, solution, buckle, strength, unifo...</td>\n",
       "      <td>[739, 740, 742, 743, 744]</td>\n",
       "      <td>[932, 744, 1050, 1172, 1171]</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>the problem of similarity for representative i...</td>\n",
       "      <td>[problem, similarity, representative, investig...</td>\n",
       "      <td>[51, 185, 874, 875, 876]</td>\n",
       "      <td>[875, 1008, 184, 864, 655]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0  189  is there a design method for calculating therm...   \n",
       "1  190  will an analysis of panel flutter based on arb...   \n",
       "2  191  what is the criterion for true panel flutter, ...   \n",
       "3  194  how can the analytical solution of the bucklin...   \n",
       "4  196  the problem of similarity for representative i...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [design, method, calculate, thermal, fatigue, ...   \n",
       "1  [analysis, panel, flutter, base, arbitrarily, ...   \n",
       "2  [criterion, true, panel, flutter, oppose, smal...   \n",
       "3  [analytical, solution, buckle, strength, unifo...   \n",
       "4  [problem, similarity, representative, investig...   \n",
       "\n",
       "                ground_truth                   jaccard_rel  jaccard_ap  \n",
       "0  [395, 866, 869, 865, 868]    [868, 1306, 833, 906, 909]    1.000000  \n",
       "1   [15, 391, 285, 390, 864]     [390, 1008, 285, 21, 391]    0.755556  \n",
       "2  [914, 915, 285, 857, 858]       [285, 31, 864, 728, 15]    1.000000  \n",
       "3  [739, 740, 742, 743, 744]  [932, 744, 1050, 1172, 1171]    0.500000  \n",
       "4   [51, 185, 874, 875, 876]    [875, 1008, 184, 864, 655]    1.000000  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding average precision for each query\n",
    "queries_val['jaccard_ap']= queries_val.apply(lambda x: average_precision(x['jaccard_rel'], x['ground_truth']), axis=1)\n",
    "queries_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d3a42f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision : 0.4431818181818181\n"
     ]
    }
   ],
   "source": [
    "#Mean average precision\n",
    "print('Mean Average Precision :', queries_val['jaccard_ap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2844f",
   "metadata": {},
   "source": [
    "#### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2ddda574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating vocabulary set\n",
    "\n",
    "vocabulary= set()\n",
    "\n",
    "for i in documents['tokens'].values:\n",
    "    vocabulary= vocabulary.union(set(i))\n",
    "    \n",
    "#sorting vocabulary alphabetically\n",
    "vocabulary= sorted(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2d30c770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary : 3042\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of vocabulary :\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c17901b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_list_doc= []\n",
    "\n",
    "#Getting term frequencies\n",
    "for tokens in documents['tokens']:\n",
    "    #Initializing a dictionary with 0 frequency- keys as terms in vocabulary, value as 0.\n",
    "    doc_dict= dict.fromkeys(vocabulary,0)\n",
    "    \n",
    "    #Counting term frequencies\n",
    "    for term in tokens:\n",
    "        doc_dict[term]+=1\n",
    "        \n",
    "    # Adding dictionary to list\n",
    "    tf_list_doc.append(doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "72923412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_list_doc) \n",
    "\n",
    "#387 is the length of documents. For each document we get a dictionary with frequency mapping of each word in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8fa3ba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (387, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablate</th>\n",
       "      <th>ablating</th>\n",
       "      <th>ablation</th>\n",
       "      <th>able</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>z</th>\n",
       "      <th>zbrozek</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3043 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid  ab  abbreviate  ability  ablate  ablating  ablation  able  abrupt  \\\n",
       "0      2   0           0        0       0         0         0     0       0   \n",
       "1      3   0           0        0       0         0         0     0       0   \n",
       "2      5   0           0        0       0         0         0     0       0   \n",
       "3      6   0           0        0       0         0         0     0       0   \n",
       "4     12   0           0        0       0         0         0     0       0   \n",
       "\n",
       "   abruptly  ...  year  yield  york  young  z  zbrozek  zero  zeroth  zone  \\\n",
       "0         0  ...     0      0     0      0  0        0     0       0     0   \n",
       "1         0  ...     0      0     0      0  0        0     0       0     0   \n",
       "2         0  ...     0      0     0      0  0        0     0       0     0   \n",
       "3         0  ...     0      0     0      0  0        0     0       0     0   \n",
       "4         0  ...     0      0     0      0  0        0     0       0     0   \n",
       "\n",
       "   zuk  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  \n",
       "\n",
       "[5 rows x 3043 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe of term frequencies for documents\n",
    "documents_tf= pd.concat([documents['docid'], pd.DataFrame(tf_list_doc)], axis=1)\n",
    "print('Shape :', documents.shape)\n",
    "documents_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "64bef00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approximation    1\n",
       "arise            1\n",
       "body             2\n",
       "boundary         5\n",
       "classical        1\n",
       "                ..\n",
       "usually          1\n",
       "viscosity        2\n",
       "viscous          2\n",
       "vorticity        2\n",
       "wave             2\n",
       "Name: 0, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_tf.loc[0,documents_tf.loc[0,:]!=0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "53669f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'approximation': 1,\n",
       " 'arise': 1,\n",
       " 'body': 2,\n",
       " 'boundary': 5,\n",
       " 'classical': 1,\n",
       " 'consequently': 1,\n",
       " 'consider': 2,\n",
       " 'constant': 1,\n",
       " 'curved': 1,\n",
       " 'different': 1,\n",
       " 'dimensional': 2,\n",
       " 'discuss': 1,\n",
       " 'discussion': 1,\n",
       " 'edge': 1,\n",
       " 'effect': 1,\n",
       " 'emit': 1,\n",
       " 'exist': 1,\n",
       " 'feature': 1,\n",
       " 'ferri': 1,\n",
       " 'flat': 3,\n",
       " 'flow': 6,\n",
       " 'fluid': 2,\n",
       " 'free': 3,\n",
       " 'high': 1,\n",
       " 'hypersonic': 2,\n",
       " 'incompressible': 2,\n",
       " 'instance': 1,\n",
       " 'investigate': 1,\n",
       " 'inviscid': 3,\n",
       " 'irrotational': 1,\n",
       " 'layer': 5,\n",
       " 'leading': 1,\n",
       " 'libby': 1,\n",
       " 'necessary': 1,\n",
       " 'nose': 1,\n",
       " 'novel': 1,\n",
       " 'original': 1,\n",
       " 'outside': 1,\n",
       " 'paper': 1,\n",
       " 'past': 4,\n",
       " 'plate': 3,\n",
       " 'possible': 1,\n",
       " 'prandtls': 2,\n",
       " 'present': 1,\n",
       " 'problem': 4,\n",
       " 'recently': 1,\n",
       " 'region': 1,\n",
       " 'restrict': 1,\n",
       " 'rotational': 2,\n",
       " 'shear': 2,\n",
       " 'shock': 2,\n",
       " 'show': 1,\n",
       " 'simple': 2,\n",
       " 'situation': 2,\n",
       " 'small': 2,\n",
       " 'somewhat': 1,\n",
       " 'speed': 1,\n",
       " 'steady': 1,\n",
       " 'stream': 3,\n",
       " 'study': 2,\n",
       " 'treat': 1,\n",
       " 'usually': 1,\n",
       " 'viscosity': 2,\n",
       " 'viscous': 2,\n",
       " 'vorticity': 2,\n",
       " 'wave': 2}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting term frequency for the first document in the dataset\n",
    "\n",
    "print('Document ID: ', documents_tf['docid'][0])\n",
    "documents_tf.loc[0, documents_tf.loc[0,:]!=0][1:].to_dict() #get all words with non-zero frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b58d5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking log normalized term frequency\n",
    "\n",
    "def log_normalize(x):\n",
    "    if x!=0:\n",
    "        return 1+ np.log10(x)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a1e546fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/578l17fj2jl3vldzwt0ww6440000gn/T/ipykernel_90445/2006667735.py:1: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  documents_tf.iloc[:,1:]= documents_tf.iloc[:, 1:].applymap(log_normalize)\n"
     ]
    }
   ],
   "source": [
    "documents_tf.iloc[:,1:]= documents_tf.iloc[:, 1:].applymap(log_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7ed7ccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'approximation': 1.0,\n",
       " 'arise': 1.0,\n",
       " 'body': 1.3010299956639813,\n",
       " 'boundary': 1.6989700043360187,\n",
       " 'classical': 1.0,\n",
       " 'consequently': 1.0,\n",
       " 'consider': 1.3010299956639813,\n",
       " 'constant': 1.0,\n",
       " 'curved': 1.0,\n",
       " 'different': 1.0,\n",
       " 'dimensional': 1.3010299956639813,\n",
       " 'discuss': 1.0,\n",
       " 'discussion': 1.0,\n",
       " 'edge': 1.0,\n",
       " 'effect': 1.0,\n",
       " 'emit': 1.0,\n",
       " 'exist': 1.0,\n",
       " 'feature': 1.0,\n",
       " 'ferri': 1.0,\n",
       " 'flat': 1.4771212547196624,\n",
       " 'flow': 1.7781512503836436,\n",
       " 'fluid': 1.3010299956639813,\n",
       " 'free': 1.4771212547196624,\n",
       " 'high': 1.0,\n",
       " 'hypersonic': 1.3010299956639813,\n",
       " 'incompressible': 1.3010299956639813,\n",
       " 'instance': 1.0,\n",
       " 'investigate': 1.0,\n",
       " 'inviscid': 1.4771212547196624,\n",
       " 'irrotational': 1.0,\n",
       " 'layer': 1.6989700043360187,\n",
       " 'leading': 1.0,\n",
       " 'libby': 1.0,\n",
       " 'necessary': 1.0,\n",
       " 'nose': 1.0,\n",
       " 'novel': 1.0,\n",
       " 'original': 1.0,\n",
       " 'outside': 1.0,\n",
       " 'paper': 1.0,\n",
       " 'past': 1.6020599913279625,\n",
       " 'plate': 1.4771212547196624,\n",
       " 'possible': 1.0,\n",
       " 'prandtls': 1.3010299956639813,\n",
       " 'present': 1.0,\n",
       " 'problem': 1.6020599913279625,\n",
       " 'recently': 1.0,\n",
       " 'region': 1.0,\n",
       " 'restrict': 1.0,\n",
       " 'rotational': 1.3010299956639813,\n",
       " 'shear': 1.3010299956639813,\n",
       " 'shock': 1.3010299956639813,\n",
       " 'show': 1.0,\n",
       " 'simple': 1.3010299956639813,\n",
       " 'situation': 1.3010299956639813,\n",
       " 'small': 1.3010299956639813,\n",
       " 'somewhat': 1.0,\n",
       " 'speed': 1.0,\n",
       " 'steady': 1.0,\n",
       " 'stream': 1.4771212547196624,\n",
       " 'study': 1.3010299956639813,\n",
       " 'treat': 1.0,\n",
       " 'usually': 1.0,\n",
       " 'viscosity': 1.3010299956639813,\n",
       " 'viscous': 1.3010299956639813,\n",
       " 'vorticity': 1.3010299956639813,\n",
       " 'wave': 1.3010299956639813}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting log normalized term frequency for the first document in the dataset\n",
    "print('Document ID: ', documents_tf['docid'][0])\n",
    "documents_tf.loc[0, documents_tf.loc[0,:]!=0][1:].to_dict() #get all words with non-zero log frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5baccded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in Query:  10 ['similarity', 'law', 'obey', 'construct', 'aeroelastic', 'model', 'heat', 'high', 'speed', 'aircraft']\n",
      "Tokens available in Vocabulary:  9 ['aircraft', 'law', 'similarity', 'construct', 'model', 'speed', 'heat', 'aeroelastic', 'high']\n"
     ]
    }
   ],
   "source": [
    "### Ranking\n",
    "\n",
    "qtokens= list(set(queries['tokens'][0]).intersection(vocabulary))\n",
    "print('Tokens in Query: ', len(queries['tokens'][0]), queries['tokens'][0])\n",
    "print('Tokens available in Vocabulary: ', len(qtokens), qtokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8ccb94",
   "metadata": {},
   "source": [
    "Here the issue we have is that not all the tokens in query are available in vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "362a0c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens not in vocabulary:  {'obey'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens not in vocabulary: \", set(queries['tokens'][0]).difference(set(qtokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07d9b2",
   "metadata": {},
   "source": [
    "The above can lead to a complete failure of our ranking model. So, we need to take an intersection of query and document vocabulary before we do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2fecd15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['docid', 'aircraft', 'law', 'similarity', 'construct', 'model', 'speed', 'heat', 'aeroelastic', 'high']\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of columns to retrieve\n",
    "columns= ['docid']\n",
    "columns.extend(qtokens)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ed72b492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>law</th>\n",
       "      <th>similarity</th>\n",
       "      <th>construct</th>\n",
       "      <th>model</th>\n",
       "      <th>speed</th>\n",
       "      <th>heat</th>\n",
       "      <th>aeroelastic</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>1.60206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid  aircraft  law  similarity  construct  model    speed      heat  \\\n",
       "0      2   0.00000  0.0         0.0        0.0    0.0  1.00000  0.000000   \n",
       "1      3   0.00000  0.0         0.0        0.0    0.0  0.00000  0.000000   \n",
       "2      5   0.00000  0.0         0.0        0.0    0.0  0.00000  1.602060   \n",
       "3      6   0.00000  0.0         0.0        0.0    0.0  0.00000  1.477121   \n",
       "4     12   1.30103  0.0         0.0        0.0    0.0  1.60206  1.000000   \n",
       "\n",
       "   aeroelastic     high  \n",
       "0      0.00000  1.00000  \n",
       "1      0.00000  0.00000  \n",
       "2      0.00000  0.00000  \n",
       "3      0.00000  0.00000  \n",
       "4      1.30103  1.60206  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now extract term frequencies for the columns\n",
    "temp_doc= documents_tf.loc[:,columns].copy()\n",
    "temp_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6470d9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>law</th>\n",
       "      <th>similarity</th>\n",
       "      <th>construct</th>\n",
       "      <th>model</th>\n",
       "      <th>speed</th>\n",
       "      <th>heat</th>\n",
       "      <th>aeroelastic</th>\n",
       "      <th>high</th>\n",
       "      <th>tf_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.602060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.477121</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.30103</td>\n",
       "      <td>1.60206</td>\n",
       "      <td>6.806180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid  aircraft  law  similarity  construct  model    speed      heat  \\\n",
       "0      2   0.00000  0.0         0.0        0.0    0.0  1.00000  0.000000   \n",
       "1      3   0.00000  0.0         0.0        0.0    0.0  0.00000  0.000000   \n",
       "2      5   0.00000  0.0         0.0        0.0    0.0  0.00000  1.602060   \n",
       "3      6   0.00000  0.0         0.0        0.0    0.0  0.00000  1.477121   \n",
       "4     12   1.30103  0.0         0.0        0.0    0.0  1.60206  1.000000   \n",
       "\n",
       "   aeroelastic     high    tf_sum  \n",
       "0      0.00000  1.00000  2.000000  \n",
       "1      0.00000  0.00000  0.000000  \n",
       "2      0.00000  0.00000  1.602060  \n",
       "3      0.00000  0.00000  1.477121  \n",
       "4      1.30103  1.60206  6.806180  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding all the frequencies\n",
    "temp_doc['tf_sum']= temp_doc[qtokens].sum(axis=1)\n",
    "temp_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d3ce88ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51,  12, 184, 364, 572])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sorting datarame according to tf_sum and getting relevant documents\n",
    "temp_doc.sort_values(by= 'tf_sum', ascending=False).head()['docid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b05d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_rank(qtokens):\n",
    "  # Getting a list of unique query terms which are present in vocabulary\n",
    "  qtokens=list(set(qtokens).intersection(vocabulary))\n",
    " \n",
    "  # Creating list of columns to retrieve\n",
    "  columns=['docid']\n",
    "  columns.extend(qtokens)\n",
    "\n",
    "  # Retireving term frequencies for query terms\n",
    "  temp_doc=documents_tf.loc[:,columns].copy()\n",
    "\n",
    "  # Adding all the frequencies\n",
    "  temp_doc['tf_sum']=temp_doc[qtokens].sum(axis=1)\n",
    "\n",
    "  # Sorting dataframe according to sum of TF and getting relevant docs\n",
    "  rel_docs=temp_doc.sort_values(by='tf_sum',ascending=False).head()['docid'].values\n",
    "\n",
    "  return rel_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8fd607c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard_rel</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>jaccard_ap</th>\n",
       "      <th>tf_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "      <td>[similarity, law, obey, construct, aeroelastic...</td>\n",
       "      <td>[12, 51, 378, 670, 875]</td>\n",
       "      <td>[184, 29, 31, 57, 378]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[51, 12, 184, 364, 572]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "      <td>[structural, aeroelastic, problem, associate, ...</td>\n",
       "      <td>[12, 51, 700, 746, 875]</td>\n",
       "      <td>[12, 746, 15, 184, 858]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[12, 172, 51, 746, 798]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "      <td>[problem, heat, conduction, composite, slab, s...</td>\n",
       "      <td>[5, 584, 6, 145, 582]</td>\n",
       "      <td>[5, 6, 90, 91, 119]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[5, 980, 584, 91, 395]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "      <td>[method, dash, exact, approximate, dash, prese...</td>\n",
       "      <td>[122, 1306, 639, 655, 988]</td>\n",
       "      <td>[48, 122, 354, 360, 1005]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[122, 234, 1104, 924, 1307]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "      <td>[real, gas, transport, property, air, availabl...</td>\n",
       "      <td>[405, 302, 436, 583, 616]</td>\n",
       "      <td>[259, 405, 302, 436, 437]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[302, 185, 616, 1009, 1313]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0    1  what similarity laws must be obeyed when const...   \n",
       "1    2  what are the structural and aeroelastic proble...   \n",
       "2    3  what problems of heat conduction in composite ...   \n",
       "3    8  what methods -dash exact or approximate -dash ...   \n",
       "4   10  are real-gas transport properties for air avai...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [similarity, law, obey, construct, aeroelastic...   \n",
       "1  [structural, aeroelastic, problem, associate, ...   \n",
       "2  [problem, heat, conduction, composite, slab, s...   \n",
       "3  [method, dash, exact, approximate, dash, prese...   \n",
       "4  [real, gas, transport, property, air, availabl...   \n",
       "\n",
       "                  jaccard_rel               ground_truth  jaccard_ap  \\\n",
       "0     [12, 51, 378, 670, 875]     [184, 29, 31, 57, 378]    0.333333   \n",
       "1     [12, 51, 700, 746, 875]    [12, 746, 15, 184, 858]    0.750000   \n",
       "2       [5, 584, 6, 145, 582]        [5, 6, 90, 91, 119]    0.833333   \n",
       "3  [122, 1306, 639, 655, 988]  [48, 122, 354, 360, 1005]    1.000000   \n",
       "4   [405, 302, 436, 583, 616]  [259, 405, 302, 436, 437]    1.000000   \n",
       "\n",
       "                        tf_rel  \n",
       "0      [51, 12, 184, 364, 572]  \n",
       "1      [12, 172, 51, 746, 798]  \n",
       "2       [5, 980, 584, 91, 395]  \n",
       "3  [122, 234, 1104, 924, 1307]  \n",
       "4  [302, 185, 616, 1009, 1313]  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ranking documents according to term frequency\n",
    "queries['tf_rel']= queries['tokens'].apply(lambda x: tf_rank(x))\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "13adb89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard_rel</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>jaccard_ap</th>\n",
       "      <th>tf_rel</th>\n",
       "      <th>tf_ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "      <td>[similarity, law, obey, construct, aeroelastic...</td>\n",
       "      <td>[12, 51, 378, 670, 875]</td>\n",
       "      <td>[184, 29, 31, 57, 378]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[51, 12, 184, 364, 572]</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "      <td>[structural, aeroelastic, problem, associate, ...</td>\n",
       "      <td>[12, 51, 700, 746, 875]</td>\n",
       "      <td>[12, 746, 15, 184, 858]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[12, 172, 51, 746, 798]</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "      <td>[problem, heat, conduction, composite, slab, s...</td>\n",
       "      <td>[5, 584, 6, 145, 582]</td>\n",
       "      <td>[5, 6, 90, 91, 119]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[5, 980, 584, 91, 395]</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "      <td>[method, dash, exact, approximate, dash, prese...</td>\n",
       "      <td>[122, 1306, 639, 655, 988]</td>\n",
       "      <td>[48, 122, 354, 360, 1005]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[122, 234, 1104, 924, 1307]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "      <td>[real, gas, transport, property, air, availabl...</td>\n",
       "      <td>[405, 302, 436, 583, 616]</td>\n",
       "      <td>[259, 405, 302, 436, 437]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[302, 185, 616, 1009, 1313]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0    1  what similarity laws must be obeyed when const...   \n",
       "1    2  what are the structural and aeroelastic proble...   \n",
       "2    3  what problems of heat conduction in composite ...   \n",
       "3    8  what methods -dash exact or approximate -dash ...   \n",
       "4   10  are real-gas transport properties for air avai...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [similarity, law, obey, construct, aeroelastic...   \n",
       "1  [structural, aeroelastic, problem, associate, ...   \n",
       "2  [problem, heat, conduction, composite, slab, s...   \n",
       "3  [method, dash, exact, approximate, dash, prese...   \n",
       "4  [real, gas, transport, property, air, availabl...   \n",
       "\n",
       "                  jaccard_rel               ground_truth  jaccard_ap  \\\n",
       "0     [12, 51, 378, 670, 875]     [184, 29, 31, 57, 378]    0.333333   \n",
       "1     [12, 51, 700, 746, 875]    [12, 746, 15, 184, 858]    0.750000   \n",
       "2       [5, 584, 6, 145, 582]        [5, 6, 90, 91, 119]    0.833333   \n",
       "3  [122, 1306, 639, 655, 988]  [48, 122, 354, 360, 1005]    1.000000   \n",
       "4   [405, 302, 436, 583, 616]  [259, 405, 302, 436, 437]    1.000000   \n",
       "\n",
       "                        tf_rel     tf_ap  \n",
       "0      [51, 12, 184, 364, 572]  0.333333  \n",
       "1      [12, 172, 51, 746, 798]  0.750000  \n",
       "2       [5, 980, 584, 91, 395]  0.750000  \n",
       "3  [122, 234, 1104, 924, 1307]  1.000000  \n",
       "4  [302, 185, 616, 1009, 1313]  1.000000  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation on Train Set\n",
    "queries['tf_ap']= queries.apply(lambda x: average_precision(x['tf_rel'], x['ground_truth']), axis=1)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0b9cb25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision : 0.5897058823529412\n"
     ]
    }
   ],
   "source": [
    "#Finding Mean average Precision\n",
    "print('Mean Average Precision :', queries['tf_ap'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6d98aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision on Validation Set : 0.44368686868686863\n"
     ]
    }
   ],
   "source": [
    "# Ranking documents according to term frequency\n",
    "queries_val['tf_rel']=queries_val['tokens'].apply(lambda x: tf_rank(x))\n",
    "\n",
    "# Finding average precision for each query\n",
    "queries_val['tf_ap']=queries_val.apply(lambda x: average_precision(x['tf_rel'],x['ground_truth']),axis=1)\n",
    "\n",
    "# Finding Mean Average Precision\n",
    "print('Mean Average Precision on Validation Set :',queries_val['tf_ap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222450df",
   "metadata": {},
   "source": [
    "#### Inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f766722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablate</th>\n",
       "      <th>ablating</th>\n",
       "      <th>ablation</th>\n",
       "      <th>able</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>z</th>\n",
       "      <th>zbrozek</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3043 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid   ab  abbreviate  ability  ablate  ablating  ablation  able  abrupt  \\\n",
       "0      2  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "1      3  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "2      5  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "3      6  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "4     12  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "\n",
       "   abruptly  ...  year  yield  york  young    z  zbrozek  zero  zeroth  zone  \\\n",
       "0       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "1       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "2       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "3       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "4       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "\n",
       "   zuk  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 3043 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term frequency of documents\n",
    "documents_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "db94ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a dictionary to store IDF values\n",
    "idf_dict= dict.fromkeys(vocabulary, 0)\n",
    "\n",
    "#Count of non-zero values per column (Document frequency)\n",
    "non_zero_count= np.count_nonzero(documents_tf.iloc[:,1:],axis=0)\n",
    "\n",
    "#Assigning IDF values\n",
    "for term, document_frequency in zip(list(vocabulary), non_zero_count):\n",
    "    idf_dict[term]= np.log10(documents.shape[0]/(document_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f4cd97df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ab': 2.28668096935493,\n",
       " 'abbreviate': 2.5877109650189114,\n",
       " 'ability': 2.5877109650189114,\n",
       " 'ablate': 2.28668096935493,\n",
       " 'ablating': 2.5877109650189114,\n",
       " 'ablation': 1.9856509736909491,\n",
       " 'able': 2.28668096935493,\n",
       " 'abrupt': 2.5877109650189114,\n",
       " 'abruptly': 2.28668096935493,\n",
       " 'absence': 2.28668096935493,\n",
       " 'absolute': 1.8887409606828927,\n",
       " 'absorb': 2.5877109650189114,\n",
       " 'absorption': 2.5877109650189114,\n",
       " 'academic': 2.5877109650189114,\n",
       " 'accelerate': 2.28668096935493,\n",
       " 'accelerated': 2.28668096935493,\n",
       " 'acceleration': 2.110589710299249,\n",
       " 'accept': 2.110589710299249,\n",
       " 'acceptability': 2.5877109650189114,\n",
       " 'acceptance': 2.5877109650189114,\n",
       " 'accessible': 2.5877109650189114,\n",
       " 'accidental': 2.5877109650189114,\n",
       " 'accommodate': 2.5877109650189114,\n",
       " 'accommodation': 2.5877109650189114,\n",
       " 'accompany': 2.28668096935493,\n",
       " 'accompanying': 2.5877109650189114,\n",
       " 'accomplish': 2.28668096935493,\n",
       " 'accord': 1.7426129250046545,\n",
       " 'accordance': 2.5877109650189114,\n",
       " 'accordingly': 1.9856509736909491,\n",
       " 'account': 1.189770956346874,\n",
       " 'accumulation': 2.28668096935493,\n",
       " 'accuracy': 1.3835909823629866,\n",
       " 'accurate': 1.6334684555795864,\n",
       " 'accurately': 1.8887409606828927,\n",
       " 'achieve': 1.5877109650189114,\n",
       " 'ackeret': 2.5877109650189114,\n",
       " 'acoustic': 1.8887409606828927,\n",
       " 'acoustical': 2.5877109650189114,\n",
       " 'acquisition': 2.5877109650189114,\n",
       " 'acr': 2.5877109650189114,\n",
       " 'acrothermoelasticity': 2.5877109650189114,\n",
       " 'act': 1.6334684555795864,\n",
       " 'action': 2.28668096935493,\n",
       " 'active': 2.110589710299249,\n",
       " 'actual': 1.6334684555795864,\n",
       " 'actually': 2.28668096935493,\n",
       " 'actural': 2.5877109650189114,\n",
       " 'adapt': 2.28668096935493,\n",
       " 'adaptable': 2.5877109650189114,\n",
       " 'adaptation': 2.5877109650189114,\n",
       " 'add': 2.110589710299249,\n",
       " 'addendum': 2.28668096935493,\n",
       " 'addition': 1.4116197059632303,\n",
       " 'additional': 1.5085297189712865,\n",
       " 'adequacy': 2.5877109650189114,\n",
       " 'adequate': 1.8095597146352678,\n",
       " 'adiabatic': 1.8887409606828927,\n",
       " 'adjacent': 1.9856509736909491,\n",
       " 'adjust': 2.5877109650189114,\n",
       " 'admit': 2.5877109650189114,\n",
       " 'admixture': 2.5877109650189114,\n",
       " 'adopt': 2.28668096935493,\n",
       " 'advance': 1.9856509736909491,\n",
       " 'advantage': 1.6334684555795864,\n",
       " 'advantageous': 2.5877109650189114,\n",
       " 'advent': 2.5877109650189114,\n",
       " 'adverse': 1.8095597146352678,\n",
       " 'advisory': 2.5877109650189114,\n",
       " 'advocate': 2.5877109650189114,\n",
       " 'aec': 2.5877109650189114,\n",
       " 'aerelastic': 2.5877109650189114,\n",
       " 'aerfoil': 2.5877109650189114,\n",
       " 'aero': 2.5877109650189114,\n",
       " 'aerodynamic': 0.9064697276433242,\n",
       " 'aerodynamically': 2.110589710299249,\n",
       " 'aeroelastic': 1.8887409606828927,\n",
       " 'aeroelasticity': 2.5877109650189114,\n",
       " 'aerofoil': 1.6846209780269679,\n",
       " 'aeronautic': 2.28668096935493,\n",
       " 'aeronautical': 2.5877109650189114,\n",
       " 'aeroplane': 2.5877109650189114,\n",
       " 'aerothermochemical': 2.5877109650189114,\n",
       " 'af': 2.5877109650189114,\n",
       " 'affect': 1.3835909823629866,\n",
       " 'affinity': 2.5877109650189114,\n",
       " 'afford': 2.5877109650189114,\n",
       " 'aforementioned': 2.5877109650189114,\n",
       " 'afresh': 2.5877109650189114,\n",
       " 'aft': 2.5877109650189114,\n",
       " 'afterbodie': 2.28668096935493,\n",
       " 'afterbody': 1.8095597146352678,\n",
       " 'afterburne': 2.5877109650189114,\n",
       " 'ago': 2.5877109650189114,\n",
       " 'agree': 1.4116197059632303,\n",
       " 'agreement': 0.9064697276433242,\n",
       " 'ahead': 1.7426129250046545,\n",
       " 'aid': 1.6334684555795864,\n",
       " 'aileron': 2.5877109650189114,\n",
       " 'aim': 2.28668096935493,\n",
       " 'air': 0.83183610934642,\n",
       " 'aircraft': 1.3324384599156054,\n",
       " 'airflow': 2.110589710299249,\n",
       " 'airfoil': 1.4737676127120747,\n",
       " 'airliner': 2.5877109650189114,\n",
       " 'airplane': 1.9856509736909491,\n",
       " 'airstream': 2.5877109650189114,\n",
       " 'aj': 2.5877109650189114,\n",
       " 'al': 2.5877109650189114,\n",
       " 'algebraic': 1.8887409606828927,\n",
       " 'allen': 2.5877109650189114,\n",
       " 'alleviate': 2.110589710299249,\n",
       " 'alleviation': 2.5877109650189114,\n",
       " 'allmovable': 2.5877109650189114,\n",
       " 'allow': 1.4415829293406734,\n",
       " 'allowance': 2.28668096935493,\n",
       " 'alloy': 1.7426129250046545,\n",
       " 'allude': 2.5877109650189114,\n",
       " 'alman': 2.5877109650189114,\n",
       " 'alter': 2.110589710299249,\n",
       " 'alternate': 2.5877109650189114,\n",
       " 'alternative': 2.28668096935493,\n",
       " 'altitude': 1.4737676127120747,\n",
       " 'aluminium': 2.110589710299249,\n",
       " 'aluminum': 1.8887409606828927,\n",
       " 'ambient': 2.110589710299249,\n",
       " 'amenable': 2.5877109650189114,\n",
       " 'america': 2.5877109650189114,\n",
       " 'ammonium': 2.5877109650189114,\n",
       " 'amount': 2.110589710299249,\n",
       " 'amplitude': 1.9856509736909491,\n",
       " 'analogous': 2.110589710299249,\n",
       " 'analogously': 2.5877109650189114,\n",
       " 'analogue': 2.110589710299249,\n",
       " 'analogy': 1.6846209780269679,\n",
       " 'analyse': 1.9856509736909491,\n",
       " 'analysis': 0.7012202398464296,\n",
       " 'analytic': 1.7426129250046545,\n",
       " 'analytical': 1.265491670284992,\n",
       " 'analytically': 1.9856509736909491,\n",
       " 'analyze': 1.4116197059632303,\n",
       " 'andhow': 2.5877109650189114,\n",
       " 'anemometer': 2.110589710299249,\n",
       " 'angle': 0.880140788920975,\n",
       " 'angled': 2.5877109650189114,\n",
       " 'angular': 2.5877109650189114,\n",
       " 'angularly': 2.5877109650189114,\n",
       " 'anh': 2.5877109650189114,\n",
       " 'annex': 2.5877109650189114,\n",
       " 'annular': 1.9856509736909491,\n",
       " 'annulus': 2.5877109650189114,\n",
       " 'anomalous': 2.5877109650189114,\n",
       " 'antisymmetrical': 2.5877109650189114,\n",
       " 'apart': 2.5877109650189114,\n",
       " 'apex': 2.28668096935493,\n",
       " 'apparatus': 2.28668096935493,\n",
       " 'apparent': 1.7426129250046545,\n",
       " 'apparently': 1.7426129250046545,\n",
       " 'appear': 1.265491670284992,\n",
       " 'appearance': 1.9856509736909491,\n",
       " 'append': 2.5877109650189114,\n",
       " 'appendice': 2.5877109650189114,\n",
       " 'appendix': 1.8095597146352678,\n",
       " 'applicability': 1.8095597146352678,\n",
       " 'applicable': 1.2259831290013186,\n",
       " 'application': 1.0436429206686357,\n",
       " 'applie': 2.5877109650189114,\n",
       " 'applied': 2.5877109650189114,\n",
       " 'apply': 0.8634350954181224,\n",
       " 'appreciable': 2.110589710299249,\n",
       " 'appreciably': 1.8887409606828927,\n",
       " 'approach': 1.3572620436406375,\n",
       " 'appropriate': 1.7426129250046545,\n",
       " 'approx': 2.5877109650189114,\n",
       " 'approximate': 0.8395229380127109,\n",
       " 'approximately': 1.0963492711846388,\n",
       " 'approximation': 0.9249531333373373,\n",
       " 'ara': 2.5877109650189114,\n",
       " 'arbitrarily': 1.9856509736909491,\n",
       " 'arbitrary': 1.3835909823629866,\n",
       " 'arc': 2.110589710299249,\n",
       " 'ardc': 2.5877109650189114,\n",
       " 'area': 1.3835909823629866,\n",
       " 'argon': 2.110589710299249,\n",
       " 'argument': 2.5877109650189114,\n",
       " 'arise': 1.4415829293406734,\n",
       " 'arithmetical': 2.5877109650189114,\n",
       " 'arrest': 2.5877109650189114,\n",
       " 'arrhenius': 2.5877109650189114,\n",
       " 'arrival': 2.5877109650189114,\n",
       " 'arrive': 2.28668096935493,\n",
       " 'arrow': 2.5877109650189114,\n",
       " 'art': 2.28668096935493,\n",
       " 'article': 2.5877109650189114,\n",
       " 'artificial': 2.110589710299249,\n",
       " 'artificially': 2.5877109650189114,\n",
       " 'ascend': 2.28668096935493,\n",
       " 'ascertain': 2.5877109650189114,\n",
       " 'ascribe': 2.5877109650189114,\n",
       " 'asme': 2.5877109650189114,\n",
       " 'aspect': 1.265491670284992,\n",
       " 'assemble': 2.5877109650189114,\n",
       " 'assess': 2.110589710299249,\n",
       " 'assessment': 2.28668096935493,\n",
       " 'assist': 2.5877109650189114,\n",
       " 'assistance': 2.5877109650189114,\n",
       " 'associate': 1.265491670284992,\n",
       " 'associated': 2.5877109650189114,\n",
       " 'assume': 0.944258288532724,\n",
       " 'assumed': 2.28668096935493,\n",
       " 'assumption': 1.1405529336766922,\n",
       " 'assure': 2.5877109650189114,\n",
       " 'asymmetrical': 2.5877109650189114,\n",
       " 'asymptote': 2.5877109650189114,\n",
       " 'asymptotic': 1.5085297189712865,\n",
       " 'atm': 2.5877109650189114,\n",
       " 'atmosphere': 1.1405529336766922,\n",
       " 'atmospheric': 1.7426129250046545,\n",
       " 'atom': 1.7426129250046545,\n",
       " 'atomic': 2.5877109650189114,\n",
       " 'attach': 1.6846209780269679,\n",
       " 'attached': 2.110589710299249,\n",
       " 'attachment': 2.110589710299249,\n",
       " 'attack': 1.0691970251410239,\n",
       " 'attainment': 2.5877109650189114,\n",
       " 'attempt': 1.6334684555795864,\n",
       " 'attendant': 2.5877109650189114,\n",
       " 'attene': 2.5877109650189114,\n",
       " 'attention': 1.7426129250046545,\n",
       " 'attenuation': 2.110589710299249,\n",
       " 'attractive': 2.5877109650189114,\n",
       " 'attributable': 2.5877109650189114,\n",
       " 'attribute': 2.110589710299249,\n",
       " 'augmentation': 2.5877109650189114,\n",
       " 'august': 2.5877109650189114,\n",
       " 'author': 1.2074997233073055,\n",
       " 'automatic': 1.9856509736909491,\n",
       " 'available': 1.2259831290013186,\n",
       " 'avaluate': 2.5877109650189114,\n",
       " 'avenue': 2.5877109650189114,\n",
       " 'average': 1.4737676127120747,\n",
       " 'avoid': 1.8095597146352678,\n",
       " 'away': 2.28668096935493,\n",
       " 'axial': 0.985650973690949,\n",
       " 'axially': 1.4737676127120747,\n",
       " 'axis': 1.5085297189712865,\n",
       " 'axisymmetric': 1.4116197059632303,\n",
       " 'axisymmetrical': 2.28668096935493,\n",
       " 'b': 1.6846209780269679,\n",
       " 'background': 2.5877109650189114,\n",
       " 'backing': 2.5877109650189114,\n",
       " 'backward': 2.5877109650189114,\n",
       " 'bagley': 2.5877109650189114,\n",
       " 'balance': 2.28668096935493,\n",
       " 'ballistic': 1.5463182798606863,\n",
       " 'ban': 2.5877109650189114,\n",
       " 'band': 1.8887409606828927,\n",
       " 'bandwidth': 2.5877109650189114,\n",
       " 'bank': 2.5877109650189114,\n",
       " 'bar': 2.5877109650189114,\n",
       " 'barrier': 2.5877109650189114,\n",
       " 'base': 0.761636162318085,\n",
       " 'basic': 1.6846209780269679,\n",
       " 'basically': 2.28668096935493,\n",
       " 'basis': 1.3324384599156054,\n",
       " 'batdorfs': 2.5877109650189114,\n",
       " 'bay': 2.110589710299249,\n",
       " 'bc': 2.5877109650189114,\n",
       " 'beam': 2.110589710299249,\n",
       " 'beane': 2.5877109650189114,\n",
       " 'bed': 2.5877109650189114,\n",
       " 'bedford': 2.5877109650189114,\n",
       " 'beg': 2.5877109650189114,\n",
       " 'begin': 1.8887409606828927,\n",
       " 'beginning': 2.28668096935493,\n",
       " 'behave': 2.28668096935493,\n",
       " 'behavior': 1.4415829293406734,\n",
       " 'behaviour': 1.5463182798606863,\n",
       " 'belief': 2.5877109650189114,\n",
       " 'believe': 1.9856509736909491,\n",
       " 'belleville': 2.5877109650189114,\n",
       " 'bend': 1.4116197059632303,\n",
       " 'bending': 1.5877109650189114,\n",
       " 'beneficial': 2.5877109650189114,\n",
       " 'berger': 2.5877109650189114,\n",
       " 'bessel': 2.28668096935493,\n",
       " 'bibliography': 2.28668096935493,\n",
       " 'bifurcation': 2.5877109650189114,\n",
       " 'billow': 2.5877109650189114,\n",
       " 'billowing': 2.5877109650189114,\n",
       " 'bimetallic': 2.5877109650189114,\n",
       " 'bimolecular': 2.5877109650189114,\n",
       " 'binary': 2.5877109650189114,\n",
       " 'biot': 2.5877109650189114,\n",
       " 'birnbaum': 2.5877109650189114,\n",
       " 'blade': 1.4415829293406734,\n",
       " 'blading': 2.5877109650189114,\n",
       " 'blasius': 2.5877109650189114,\n",
       " 'blast': 1.9856509736909491,\n",
       " 'bleed': 2.28668096935493,\n",
       " 'bleich': 2.5877109650189114,\n",
       " 'blockage': 1.8887409606828927,\n",
       " 'blow': 2.5877109650189114,\n",
       " 'blowing': 2.5877109650189114,\n",
       " 'blunt': 0.964461674621011,\n",
       " 'blunted': 2.5877109650189114,\n",
       " 'blunter': 2.5877109650189114,\n",
       " 'bluntness': 2.110589710299249,\n",
       " 'boattail': 2.5877109650189114,\n",
       " 'body': 0.6286695726978178,\n",
       " 'bomber': 2.28668096935493,\n",
       " 'bond': 2.5877109650189114,\n",
       " 'bonus': 2.5877109650189114,\n",
       " 'book': 2.5877109650189114,\n",
       " 'boom': 1.9856509736909491,\n",
       " 'boost': 2.5877109650189114,\n",
       " 'bound': 2.110589710299249,\n",
       " 'boundary': 0.46060616665410375,\n",
       " 'bow': 1.6846209780269679,\n",
       " 'bracket': 2.5877109650189114,\n",
       " 'brake': 2.5877109650189114,\n",
       " 'branch': 2.5877109650189114,\n",
       " 'break': 2.110589710299249,\n",
       " 'breakdown': 2.5877109650189114,\n",
       " 'breguet': 2.5877109650189114,\n",
       " 'bridge': 2.5877109650189114,\n",
       " 'brief': 1.5085297189712865,\n",
       " 'briefly': 1.5085297189712865,\n",
       " 'bring': 1.9856509736909491,\n",
       " 'british': 2.5877109650189114,\n",
       " 'broad': 2.5877109650189114,\n",
       " 'broaden': 2.5877109650189114,\n",
       " 'brown': 2.5877109650189114,\n",
       " 'btulb': 2.5877109650189114,\n",
       " 'bubble': 2.5877109650189114,\n",
       " 'buckle': 0.964461674621011,\n",
       " 'buckled': 2.110589710299249,\n",
       " 'buckling': 0.9966463579924122,\n",
       " 'budiansky': 2.5877109650189114,\n",
       " 'buffet': 2.28668096935493,\n",
       " 'buffeting': 2.28668096935493,\n",
       " 'build': 1.9856509736909491,\n",
       " 'bulk': 2.28668096935493,\n",
       " 'bulkhead': 2.5877109650189114,\n",
       " 'bullet': 2.5877109650189114,\n",
       " 'buoyant': 2.28668096935493,\n",
       " 'bureau': 2.28668096935493,\n",
       " 'burning': 2.5877109650189114,\n",
       " 'busemann': 2.28668096935493,\n",
       " 'bypass': 2.5877109650189114,\n",
       " 'c': 1.9856509736909491,\n",
       " 'cal': 2.28668096935493,\n",
       " 'calculate': 0.880140788920975,\n",
       " 'calculated': 2.5877109650189114,\n",
       " 'calculation': 0.8473482755246675,\n",
       " 'calculus': 2.5877109650189114,\n",
       " 'calibrate': 2.28668096935493,\n",
       " 'calibration': 2.110589710299249,\n",
       " 'california': 2.5877109650189114,\n",
       " 'call': 1.9856509736909491,\n",
       " 'caloric': 2.5877109650189114,\n",
       " 'camber': 2.28668096935493,\n",
       " 'cantilever': 2.110589710299249,\n",
       " 'cap': 1.9856509736909491,\n",
       " 'capability': 2.5877109650189114,\n",
       " 'capacitance': 2.28668096935493,\n",
       " 'capacity': 1.9856509736909491,\n",
       " 'carbon': 2.5877109650189114,\n",
       " 'carbonate': 2.5877109650189114,\n",
       " 'careful': 2.28668096935493,\n",
       " 'carefully': 2.5877109650189114,\n",
       " 'carry': 1.3089573640660825,\n",
       " 'cartesian': 2.5877109650189114,\n",
       " 'cascade': 1.8887409606828927,\n",
       " 'case': 0.5583271873337018,\n",
       " 'catalytic': 2.5877109650189114,\n",
       " 'category': 2.28668096935493,\n",
       " 'cause': 1.2866809693549301,\n",
       " 'cease': 2.5877109650189114,\n",
       " 'cent': 1.5463182798606863,\n",
       " 'center': 1.6846209780269679,\n",
       " 'centerline': 2.5877109650189114,\n",
       " 'central': 2.110589710299249,\n",
       " 'centrally': 2.5877109650189114,\n",
       " 'centre': 2.28668096935493,\n",
       " 'centrifugal': 1.8887409606828927,\n",
       " 'certain': 1.189770956346874,\n",
       " 'certainly': 2.5877109650189114,\n",
       " 'ceuler': 2.5877109650189114,\n",
       " 'change': 1.0825609866990054,\n",
       " 'channel': 2.110589710299249,\n",
       " 'chapman': 2.28668096935493,\n",
       " 'chapter': 2.5877109650189114,\n",
       " 'character': 1.8095597146352678,\n",
       " 'characteristic': 1.0562320479766563,\n",
       " 'characterize': 1.8887409606828927,\n",
       " 'charge': 2.28668096935493,\n",
       " 'chart': 1.5463182798606863,\n",
       " 'chartsfig': 2.5877109650189114,\n",
       " 'check': 1.6334684555795864,\n",
       " 'chemical': 1.5877109650189114,\n",
       " 'chemically': 2.28668096935493,\n",
       " 'cheng': 2.28668096935493,\n",
       " 'chesky': 2.5877109650189114,\n",
       " 'chiefly': 2.5877109650189114,\n",
       " 'chloride': 2.5877109650189114,\n",
       " 'choice': 1.8095597146352678,\n",
       " 'choke': 2.28668096935493,\n",
       " 'choleski': 2.5877109650189114,\n",
       " 'choose': 1.6334684555795864,\n",
       " 'chord': 1.6846209780269679,\n",
       " 'chordwise': 1.6846209780269679,\n",
       " 'circular': 0.9064697276433242,\n",
       " 'circulatory': 2.5877109650189114,\n",
       " 'circumference': 2.28668096935493,\n",
       " 'circumferential': 1.5463182798606863,\n",
       " 'circumscribing': 2.28668096935493,\n",
       " 'circumstance': 2.28668096935493,\n",
       " 'cite': 2.28668096935493,\n",
       " 'claim': 2.28668096935493,\n",
       " 'clamp': 1.4737676127120747,\n",
       " 'clamped': 2.5877109650189114,\n",
       " 'clarify': 2.5877109650189114,\n",
       " 'class': 1.7426129250046545,\n",
       " 'classical': 1.5463182798606863,\n",
       " 'classically': 2.5877109650189114,\n",
       " 'classificaiton': 2.5877109650189114,\n",
       " 'classification': 2.5877109650189114,\n",
       " 'classify': 2.5877109650189114,\n",
       " 'clear': 2.110589710299249,\n",
       " 'clearly': 1.8887409606828927,\n",
       " 'close': 1.3572620436406375,\n",
       " 'closed': 1.7426129250046545,\n",
       " 'closely': 1.6334684555795864,\n",
       " 'co': 2.110589710299249,\n",
       " 'coaxial': 2.28668096935493,\n",
       " 'coefficient': 0.8095597146352678,\n",
       " 'coefstant': 2.5877109650189114,\n",
       " 'coincide': 2.28668096935493,\n",
       " 'cold': 1.9856509736909491,\n",
       " 'colder': 2.5877109650189114,\n",
       " 'collaborator': 2.5877109650189114,\n",
       " 'collect': 2.28668096935493,\n",
       " 'collision': 2.28668096935493,\n",
       " 'column': 1.5877109650189114,\n",
       " 'combination': 1.3324384599156054,\n",
       " 'combine': 1.5463182798606863,\n",
       " 'combined': 2.110589710299249,\n",
       " 'combustion': 2.5877109650189114,\n",
       " 'comment': 2.28668096935493,\n",
       " 'commercial': 2.5877109650189114,\n",
       " 'commercially': 2.5877109650189114,\n",
       " 'committee': 2.5877109650189114,\n",
       " 'common': 1.8887409606828927,\n",
       " 'commonly': 2.28668096935493,\n",
       " 'communication': 2.5877109650189114,\n",
       " 'comparable': 1.7426129250046545,\n",
       " 'comparative': 2.28668096935493,\n",
       " 'comparatively': 2.28668096935493,\n",
       " 'compare': 0.7681670294770427,\n",
       " 'comparison': 1.0079273684021013,\n",
       " 'compatibility': 2.5877109650189114,\n",
       " 'compatible': 2.5877109650189114,\n",
       " 'compete': 2.5877109650189114,\n",
       " 'compilation': 2.110589710299249,\n",
       " 'compile': 2.28668096935493,\n",
       " 'complement': 2.5877109650189114,\n",
       " 'complementary': 2.5877109650189114,\n",
       " 'complete': 1.3324384599156054,\n",
       " 'completely': 1.8095597146352678,\n",
       " 'complex': 1.6846209780269679,\n",
       " 'complicate': 2.5877109650189114,\n",
       " 'complicated': 2.28668096935493,\n",
       " 'component': 1.3089573640660825,\n",
       " 'composite': 2.110589710299249,\n",
       " 'composition': 1.6846209780269679,\n",
       " 'compress': 1.7426129250046545,\n",
       " 'compressed': 2.5877109650189114,\n",
       " 'compressibility': 1.6846209780269679,\n",
       " 'compressible': 1.189770956346874,\n",
       " 'compression': 1.3324384599156054,\n",
       " 'compressive': 1.5463182798606863,\n",
       " 'compressor': 1.8887409606828927,\n",
       " 'comprise': 2.28668096935493,\n",
       " 'comprised': 2.5877109650189114,\n",
       " 'compromise': 2.28668096935493,\n",
       " 'computation': 1.7426129250046545,\n",
       " 'computational': 2.5877109650189114,\n",
       " 'compute': 1.5463182798606863,\n",
       " 'computer': 1.6846209780269679,\n",
       " 'computing': 1.9856509736909491,\n",
       " 'con': 2.5877109650189114,\n",
       " 'concave': 2.28668096935493,\n",
       " 'conceive': 2.5877109650189114,\n",
       " 'concentrate': 2.110589710299249,\n",
       " 'concentrated': 2.5877109650189114,\n",
       " 'concentration': 1.8095597146352678,\n",
       " 'concept': 1.3835909823629866,\n",
       " 'conception': 2.5877109650189114,\n",
       " 'concern': 1.265491670284992,\n",
       " 'concerned': 2.5877109650189114,\n",
       " 'conclude': 1.3572620436406375,\n",
       " 'conclusion': 1.5877109650189114,\n",
       " 'concoct': 2.5877109650189114,\n",
       " 'concrete': 2.5877109650189114,\n",
       " 'concurrently': 2.5877109650189114,\n",
       " 'condensation': 2.5877109650189114,\n",
       " 'condense': 2.5877109650189114,\n",
       " 'condition': 0.6634316789570297,\n",
       " 'conduct': 1.2452882841967052,\n",
       " 'conduction': 1.6334684555795864,\n",
       " 'conductivity': 1.9856509736909491,\n",
       " 'cone': 0.915613107083194,\n",
       " 'confidence': 2.5877109650189114,\n",
       " 'configuration': 1.3835909823629866,\n",
       " 'confine': 2.5877109650189114,\n",
       " 'confirm': 1.9856509736909491,\n",
       " 'confirmation': 2.5877109650189114,\n",
       " 'conflict': 2.5877109650189114,\n",
       " 'confluent': 2.5877109650189114,\n",
       " 'conic': 2.5877109650189114,\n",
       " 'conical': 1.3572620436406375,\n",
       " 'conidtion': 2.5877109650189114,\n",
       " 'conjecture': 2.28668096935493,\n",
       " 'conjunction': 1.8887409606828927,\n",
       " 'connect': 2.28668096935493,\n",
       " 'connection': 1.8095597146352678,\n",
       " 'consequence': 1.8095597146352678,\n",
       " 'consequent': 2.28668096935493,\n",
       " 'consequently': 2.110589710299249,\n",
       " 'conservation': 2.28668096935493,\n",
       " 'conservative': 2.110589710299249,\n",
       " 'consider': 0.7815309910350242,\n",
       " 'considerable': 1.5085297189712865,\n",
       " 'considerably': 1.6334684555795864,\n",
       " 'consideration': 1.2259831290013186,\n",
       " 'consist': 1.4737676127120747,\n",
       " 'consistent': 1.7426129250046545,\n",
       " 'consistently': 2.28668096935493,\n",
       " 'constancy': 2.5877109650189114,\n",
       " 'constant': 0.8887409606828927,\n",
       " 'constituent': 2.28668096935493,\n",
       " 'constitute': 2.5877109650189114,\n",
       " 'constraint': 1.9856509736909491,\n",
       " 'construct': 1.8887409606828927,\n",
       " 'construction': 1.9856509736909491,\n",
       " 'contact': 2.110589710299249,\n",
       " 'contain': 1.6334684555795864,\n",
       " 'continuation': 2.5877109650189114,\n",
       " 'continue': 2.28668096935493,\n",
       " 'continued': 2.5877109650189114,\n",
       " 'continuity': 2.5877109650189114,\n",
       " 'continuous': 1.5463182798606863,\n",
       " 'continuously': 2.5877109650189114,\n",
       " 'continuum': 1.9856509736909491,\n",
       " 'contour': 2.5877109650189114,\n",
       " 'contract': 2.5877109650189114,\n",
       " 'contraction': 1.8887409606828927,\n",
       " 'contradiction': 2.5877109650189114,\n",
       " 'contrary': 1.9856509736909491,\n",
       " 'contrast': 2.5877109650189114,\n",
       " 'contribute': 2.5877109650189114,\n",
       " 'contribution': 1.7426129250046545,\n",
       " 'control': 1.4116197059632303,\n",
       " 'controlling': 2.5877109650189114,\n",
       " 'convection': 1.6846209780269679,\n",
       " 'convective': 2.28668096935493,\n",
       " 'convenience': 2.5877109650189114,\n",
       " 'convenient': 1.8887409606828927,\n",
       " 'conventional': 1.8095597146352678,\n",
       " 'convergence': 1.8887409606828927,\n",
       " 'convergent': 2.28668096935493,\n",
       " 'converging': 2.28668096935493,\n",
       " 'converse': 2.5877109650189114,\n",
       " 'conversely': 2.5877109650189114,\n",
       " 'conversion': 2.28668096935493,\n",
       " 'convex': 2.5877109650189114,\n",
       " 'conviction': 2.5877109650189114,\n",
       " 'cool': 1.2452882841967052,\n",
       " 'coolant': 1.9856509736909491,\n",
       " 'cooled': 2.5877109650189114,\n",
       " 'cooler': 2.5877109650189114,\n",
       " 'cooling': 1.8095597146352678,\n",
       " 'cooperation': 2.28668096935493,\n",
       " 'coordinate': 1.7426129250046545,\n",
       " 'cope': 2.5877109650189114,\n",
       " 'copper': 2.5877109650189114,\n",
       " 'core': 1.8095597146352678,\n",
       " 'corner': 2.28668096935493,\n",
       " 'corporation': 2.5877109650189114,\n",
       " 'corpuscular': 2.5877109650189114,\n",
       " 'correct': 1.5085297189712865,\n",
       " 'correction': 1.5085297189712865,\n",
       " 'correctly': 1.8887409606828927,\n",
       " 'correlate': 1.5877109650189114,\n",
       " 'correlation': 1.4415829293406734,\n",
       " 'correspond': 1.3089573640660825,\n",
       " 'corresponding': 1.6846209780269679,\n",
       " 'correspondingly': 2.28668096935493,\n",
       " 'corroborate': 2.5877109650189114,\n",
       " 'corrugate': 2.110589710299249,\n",
       " 'couette': 2.5877109650189114,\n",
       " 'coundary': 2.5877109650189114,\n",
       " 'counter': 2.5877109650189114,\n",
       " 'country': 2.5877109650189114,\n",
       " 'couple': 2.110589710299249,\n",
       " 'coupled': 2.5877109650189114,\n",
       " 'coupling': 2.110589710299249,\n",
       " 'coupon': 2.5877109650189114,\n",
       " 'course': 2.5877109650189114,\n",
       " 'cover': 1.3835909823629866,\n",
       " 'cp': 2.5877109650189114,\n",
       " 'crabtree': 2.5877109650189114,\n",
       " 'crack': 2.5877109650189114,\n",
       " 'crank': 2.5877109650189114,\n",
       " 'creased': 2.5877109650189114,\n",
       " 'creep': 1.5463182798606863,\n",
       " 'criterion': 1.7426129250046545,\n",
       " 'critical': 1.265491670284992,\n",
       " 'critically': 2.28668096935493,\n",
       " 'crocco': 1.9856509736909491,\n",
       " 'croccos': 2.5877109650189114,\n",
       " 'cropped': 2.5877109650189114,\n",
       " 'cross': 1.3835909823629866,\n",
       " 'crossflow': 2.110589710299249,\n",
       " 'crucial': 2.5877109650189114,\n",
       " 'cruise': 2.28668096935493,\n",
       " 'cumulative': 2.28668096935493,\n",
       " 'current': 1.8095597146352678,\n",
       " 'currently': 2.110589710299249,\n",
       " 'curvature': 1.2866809693549301,\n",
       " 'curve': 1.0963492711846388,\n",
       " 'curved': 1.6334684555795864,\n",
       " 'customary': 2.28668096935493,\n",
       " 'cycle': 1.9856509736909491,\n",
       " 'cyclic': 2.28668096935493,\n",
       " 'cycling': 2.5877109650189114,\n",
       " 'cylinder': 0.7815309910350242,\n",
       " 'cylindrical': 1.1405529336766922,\n",
       " 'd': 2.28668096935493,\n",
       " 'daley': 2.5877109650189114,\n",
       " 'damage': 2.110589710299249,\n",
       " 'damaging': 2.5877109650189114,\n",
       " 'damp': 1.7426129250046545,\n",
       " 'damping': 2.28668096935493,\n",
       " 'dana': 2.5877109650189114,\n",
       " 'dash': 2.110589710299249,\n",
       " 'dashin': 2.5877109650189114,\n",
       " 'dashthat': 2.5877109650189114,\n",
       " 'dashthe': 2.5877109650189114,\n",
       " 'data': 2.28668096935493,\n",
       " 'date': 2.28668096935493,\n",
       " 'datum': 0.8395229380127109,\n",
       " 'de': 2.5877109650189114,\n",
       " 'dead': 2.110589710299249,\n",
       " 'deal': 1.4737676127120747,\n",
       " 'debatable': 2.5877109650189114,\n",
       " 'decay': 2.28668096935493,\n",
       " 'decelerate': 2.5877109650189114,\n",
       " 'deceleration': 2.28668096935493,\n",
       " 'decide': 2.5877109650189114,\n",
       " 'decrease': 1.2074997233073055,\n",
       " 'decrement': 2.5877109650189114,\n",
       " 'deduce': 1.8887409606828927,\n",
       " 'defect': 2.28668096935493,\n",
       " 'defference': 2.5877109650189114,\n",
       " 'deficiency': 1.9856509736909491,\n",
       " 'deficit': 2.5877109650189114,\n",
       " 'definable': 2.5877109650189114,\n",
       " 'define': 1.4415829293406734,\n",
       " 'definite': 2.28668096935493,\n",
       " 'definitely': 2.28668096935493,\n",
       " 'deflection': 1.189770956346874,\n",
       " 'deform': 2.28668096935493,\n",
       " 'deformation': 1.3089573640660825,\n",
       " 'deformed': 2.5877109650189114,\n",
       " 'defy': 2.5877109650189114,\n",
       " 'deg': 1.9856509736909491,\n",
       " 'degree': 1.2866809693549301,\n",
       " 'degreek': 2.110589710299249,\n",
       " 'delay': 1.8095597146352678,\n",
       " 'delft': 2.5877109650189114,\n",
       " 'delineate': 2.5877109650189114,\n",
       " 'delta': 1.4737676127120747,\n",
       " 'demand': 2.5877109650189114,\n",
       " 'demonstrate': 1.5877109650189114,\n",
       " 'denote': 2.28668096935493,\n",
       " 'density': 1.2452882841967052,\n",
       " 'depart': 2.5877109650189114,\n",
       " 'department': 2.5877109650189114,\n",
       " 'departure': 2.5877109650189114,\n",
       " 'depend': 1.3324384599156054,\n",
       " 'dependence': 1.8887409606828927,\n",
       " 'dependent': 1.4116197059632303,\n",
       " 'depletion': 2.5877109650189114,\n",
       " 'depth': 2.5877109650189114,\n",
       " 'derivable': 2.5877109650189114,\n",
       " 'derivation': 1.8887409606828927,\n",
       " 'derivative': 1.8095597146352678,\n",
       " 'derive': 0.9966463579924122,\n",
       " 'des': 2.5877109650189114,\n",
       " 'descend': 2.28668096935493,\n",
       " 'descent': 2.5877109650189114,\n",
       " 'describe': 0.985650973690949,\n",
       " 'description': 1.6334684555795864,\n",
       " 'design': 0.964461674621011,\n",
       " 'designer': 2.110589710299249,\n",
       " 'desirability': 2.5877109650189114,\n",
       " 'desirable': 2.28668096935493,\n",
       " 'desire': 2.28668096935493,\n",
       " 'despite': 2.5877109650189114,\n",
       " 'destabilizing': 2.28668096935493,\n",
       " 'detach': 1.8095597146352678,\n",
       " 'detachment': 2.110589710299249,\n",
       " 'detail': 1.189770956346874,\n",
       " 'detailed': 1.7426129250046545,\n",
       " 'detect': 2.5877109650189114,\n",
       " 'determinable': 2.5877109650189114,\n",
       " 'determination': 1.3089573640660825,\n",
       " 'determine': 0.7012202398464296,\n",
       " 'determined': 1.9856509736909491,\n",
       " 'detra': 2.5877109650189114,\n",
       " 'deuce': 2.5877109650189114,\n",
       " 'develop': 0.8095597146352678,\n",
       " 'developable': 2.5877109650189114,\n",
       " 'development': 1.110589710299249,\n",
       " 'deviate': 2.5877109650189114,\n",
       " 'deviation': 1.8095597146352678,\n",
       " 'device': 2.28668096935493,\n",
       " 'devise': 2.110589710299249,\n",
       " 'devote': 2.110589710299249,\n",
       " 'diagram': 2.28668096935493,\n",
       " 'diameter': 1.4415829293406734,\n",
       " 'diaphragm': 2.5877109650189114,\n",
       " 'differ': 1.5463182798606863,\n",
       " 'difference': 1.1253129671199553,\n",
       " 'different': 1.1405529336766922,\n",
       " 'differential': 1.1727376170480934,\n",
       " 'differentiate': 2.5877109650189114,\n",
       " 'difficult': 1.8887409606828927,\n",
       " 'difficulty': 1.7426129250046545,\n",
       " 'diffuser': 2.5877109650189114,\n",
       " 'diffusion': 1.9856509736909491,\n",
       " 'digital': 2.110589710299249,\n",
       " 'dihedral': 2.5877109650189114,\n",
       " 'dimension': 1.8887409606828927,\n",
       " 'dimensional': 0.8095597146352678,\n",
       " 'dimensionless': 1.7426129250046545,\n",
       " 'diminish': 1.8095597146352678,\n",
       " 'dioxide': 2.5877109650189114,\n",
       " 'direct': 1.7426129250046545,\n",
       " 'direction': 1.2259831290013186,\n",
       " 'directly': 1.8095597146352678,\n",
       " 'disadvantage': 2.5877109650189114,\n",
       " 'disagreement': 2.5877109650189114,\n",
       " 'disappear': 2.5877109650189114,\n",
       " 'disc': 2.5877109650189114,\n",
       " 'discharge': 2.28668096935493,\n",
       " 'disclose': 2.5877109650189114,\n",
       " 'discontinuity': 1.9856509736909491,\n",
       " 'discontinuous': 2.28668096935493,\n",
       " 'discover': 2.28668096935493,\n",
       " 'discovery': 2.5877109650189114,\n",
       " 'discrepancy': 1.8095597146352678,\n",
       " 'discrete': 1.8095597146352678,\n",
       " 'discuss': 0.7243881048984555,\n",
       " 'discussion': 1.2074997233073055,\n",
       " 'disk': 1.9856509736909491,\n",
       " 'displace': 2.28668096935493,\n",
       " 'displacement': 1.189770956346874,\n",
       " 'display': 2.5877109650189114,\n",
       " 'disregard': 2.5877109650189114,\n",
       " 'dissipation': 2.110589710299249,\n",
       " 'dissipative': 2.110589710299249,\n",
       " 'dissociate': 1.7426129250046545,\n",
       " 'dissociation': 1.7426129250046545,\n",
       " 'distance': 1.0436429206686357,\n",
       " 'distinct': 2.28668096935493,\n",
       " 'distinction': 2.5877109650189114,\n",
       " 'distinctly': 2.5877109650189114,\n",
       " 'distinguish': 2.28668096935493,\n",
       " 'distortion': 1.8095597146352678,\n",
       " 'distribute': 1.8095597146352678,\n",
       " 'distribution': 0.6192280164649763,\n",
       " 'disturb': 2.5877109650189114,\n",
       " 'disturbance': 1.4737676127120747,\n",
       " 'diverge': 2.28668096935493,\n",
       " 'divergence': 1.8095597146352678,\n",
       " 'divergent': 2.28668096935493,\n",
       " 'diversified': 2.5877109650189114,\n",
       " 'divide': 1.7426129250046545,\n",
       " 'division': 2.28668096935493,\n",
       " 'doctor': 2.5877109650189114,\n",
       " 'domain': 2.5877109650189114,\n",
       " 'dominant': 2.110589710299249,\n",
       " 'dominate': 2.110589710299249,\n",
       " 'donnell': 1.6334684555795864,\n",
       " 'donnells': 2.110589710299249,\n",
       " 'double': 1.8887409606828927,\n",
       " 'doublet': 2.5877109650189114,\n",
       " 'doubt': 2.110589710299249,\n",
       " 'downstream': 1.4415829293406734,\n",
       " 'downwash': 1.9856509736909491,\n",
       " 'drag': 1.2259831290013186,\n",
       " 'drastic': 2.5877109650189114,\n",
       " 'drastically': 2.5877109650189114,\n",
       " 'draw': 1.8095597146352678,\n",
       " 'driest': 2.5877109650189114,\n",
       " 'drift': 2.5877109650189114,\n",
       " 'drive': 2.28668096935493,\n",
       " 'driver': 2.5877109650189114,\n",
       " 'droop': 2.5877109650189114,\n",
       " 'drooped': 2.5877109650189114,\n",
       " 'drop': 2.110589710299249,\n",
       " 'dropoff': 2.5877109650189114,\n",
       " 'dudx': 2.5877109650189114,\n",
       " 'dufour': 2.5877109650189114,\n",
       " 'duration': 2.110589710299249,\n",
       " 'dvl': 2.5877109650189114,\n",
       " 'dyke': 2.110589710299249,\n",
       " 'dynamic': 1.2259831290013186,\n",
       " 'e': 1.5463182798606863,\n",
       " 'early': 1.6334684555795864,\n",
       " 'earth': 1.8095597146352678,\n",
       " 'ease': 2.5877109650189114,\n",
       " 'easily': 1.9856509736909491,\n",
       " 'easy': 2.110589710299249,\n",
       " 'ebb': 2.5877109650189114,\n",
       " 'eccentricity': 1.9856509736909491,\n",
       " 'eckert': 2.5877109650189114,\n",
       " 'economic': 2.5877109650189114,\n",
       " 'economical': 2.5877109650189114,\n",
       " 'eddy': 2.5877109650189114,\n",
       " 'edge': 0.7488618742816561,\n",
       " 'edgewise': 2.5877109650189114,\n",
       " 'effect': 0.4323749275538496,\n",
       " 'effective': 1.5877109650189114,\n",
       " 'effectiveness': 2.110589710299249,\n",
       " 'efficacious': 2.5877109650189114,\n",
       " 'efficiency': 2.110589710299249,\n",
       " 'efficient': 1.8095597146352678,\n",
       " 'efflux': 2.5877109650189114,\n",
       " 'effort': 1.9856509736909491,\n",
       " 'effusion': 2.5877109650189114,\n",
       " 'eg': 1.9856509736909491,\n",
       " 'egger': 2.5877109650189114,\n",
       " 'eh': 2.5877109650189114,\n",
       " 'eigenvalue': 2.5877109650189114,\n",
       " 'eigenvector': 2.5877109650189114,\n",
       " 'eighth': 2.28668096935493,\n",
       " 'ejector': 2.5877109650189114,\n",
       " 'elaborate': 2.5877109650189114,\n",
       " 'elastic': 1.2452882841967052,\n",
       " 'elastically': 2.5877109650189114,\n",
       " 'elasticity': 2.28668096935493,\n",
       " 'electric': 2.110589710299249,\n",
       " 'electrical': 1.9856509736909491,\n",
       " 'electrically': 1.8887409606828927,\n",
       " 'electromagnetic': 2.5877109650189114,\n",
       " 'electron': 2.28668096935493,\n",
       " 'electronic': 2.110589710299249,\n",
       " 'element': 1.7426129250046545,\n",
       " 'elemental': 2.5877109650189114,\n",
       " 'elementary': 2.5877109650189114,\n",
       " 'elevate': 2.5877109650189114,\n",
       " 'elevator': 2.5877109650189114,\n",
       " 'eliminate': 1.8887409606828927,\n",
       " 'ellipse': 2.5877109650189114,\n",
       " 'ellipsoidal': 2.5877109650189114,\n",
       " 'elliptic': 1.7426129250046545,\n",
       " 'elliptical': 2.28668096935493,\n",
       " 'elliptically': 2.5877109650189114,\n",
       " 'ellipticity': 2.5877109650189114,\n",
       " 'embed': 2.5877109650189114,\n",
       " 'embrace': 2.5877109650189114,\n",
       " 'emission': 2.5877109650189114,\n",
       " 'emissivity': 2.5877109650189114,\n",
       " 'emit': 2.5877109650189114,\n",
       " 'emmon': 2.5877109650189114,\n",
       " 'emphasis': 2.28668096935493,\n",
       " 'emphasise': 2.5877109650189114,\n",
       " 'emphasize': 1.8887409606828927,\n",
       " 'empirical': 1.6334684555795864,\n",
       " 'empiricalintermediate': 2.5877109650189114,\n",
       " 'employ': 1.5085297189712865,\n",
       " 'enable': 1.7426129250046545,\n",
       " 'encircle': 2.5877109650189114,\n",
       " 'enclose': 2.5877109650189114,\n",
       " 'encompass': 2.28668096935493,\n",
       " 'encounter': 1.7426129250046545,\n",
       " 'encouraging': 2.5877109650189114,\n",
       " 'end': 1.4415829293406734,\n",
       " 'endeavour': 2.5877109650189114,\n",
       " 'endplate': 2.5877109650189114,\n",
       " 'energy': 1.2866809693549301,\n",
       " 'enforce': 2.5877109650189114,\n",
       " 'engage': 2.5877109650189114,\n",
       " 'engesser': 2.5877109650189114,\n",
       " 'engine': 1.8887409606828927,\n",
       " 'engineer': 2.110589710299249,\n",
       " 'engineering': 1.9856509736909491,\n",
       " 'enjoy': 2.5877109650189114,\n",
       " 'enlarge': 2.5877109650189114,\n",
       " 'enlighten': 2.5877109650189114,\n",
       " 'enquiry': 2.5877109650189114,\n",
       " 'enter': 1.4737676127120747,\n",
       " 'enthalpic': 2.5877109650189114,\n",
       " 'enthalpy': 1.5085297189712865,\n",
       " 'enthalpyuse': 2.5877109650189114,\n",
       " 'entire': 1.5877109650189114,\n",
       " 'entirely': 2.110589710299249,\n",
       " 'entrance': 2.5877109650189114,\n",
       " 'entropy': 1.8095597146352678,\n",
       " 'entry': 1.4737676127120747,\n",
       " 'envelope': 2.28668096935493,\n",
       " 'environment': 2.28668096935493,\n",
       " 'environmental': 2.5877109650189114,\n",
       " 'envisage': 2.5877109650189114,\n",
       " 'equal': 1.4737676127120747,\n",
       " 'equality': 2.5877109650189114,\n",
       " 'equally': 2.28668096935493,\n",
       " 'equation': 0.570677625720131,\n",
       " 'equilibrate': 2.5877109650189114,\n",
       " 'equilibrium': 1.1405529336766922,\n",
       " 'equipment': 1.8887409606828927,\n",
       " 'equivalence': 2.5877109650189114,\n",
       " 'equivalent': 1.4116197059632303,\n",
       " 'er': 2.5877109650189114,\n",
       " 'erature': 2.5877109650189114,\n",
       " 'erickson': 2.5877109650189114,\n",
       " 'erosive': 2.5877109650189114,\n",
       " 'error': 1.6846209780269679,\n",
       " 'escape': 2.5877109650189114,\n",
       " 'especially': 1.8095597146352678,\n",
       " 'essence': 2.5877109650189114,\n",
       " 'essential': 1.8095597146352678,\n",
       " 'essentially': 1.4415829293406734,\n",
       " 'establish': 1.4116197059632303,\n",
       " 'establishment': 2.5877109650189114,\n",
       " 'estimate': 1.1405529336766922,\n",
       " 'et': 2.5877109650189114,\n",
       " 'etc': 2.110589710299249,\n",
       " 'ethylene': 2.5877109650189114,\n",
       " 'ev': 2.5877109650189114,\n",
       " 'evaluate': 1.4737676127120747,\n",
       " 'evaluation': 1.7426129250046545,\n",
       " 'evaporate': 2.5877109650189114,\n",
       " 'evaporation': 2.5877109650189114,\n",
       " 'eventual': 2.5877109650189114,\n",
       " 'evidence': 1.6846209780269679,\n",
       " 'evident': 2.5877109650189114,\n",
       " 'exact': 1.0963492711846388,\n",
       " 'exactly': 2.28668096935493,\n",
       " 'examination': 2.110589710299249,\n",
       " 'examine': 1.5085297189712865,\n",
       " 'example': 1.0825609866990054,\n",
       " 'exceed': 1.8095597146352678,\n",
       " 'excellent': 2.28668096935493,\n",
       " 'exceptionally': 2.5877109650189114,\n",
       " 'excess': 2.5877109650189114,\n",
       " 'excessive': 2.5877109650189114,\n",
       " 'exchange': 2.5877109650189114,\n",
       " 'excitation': 2.5877109650189114,\n",
       " 'excite': 1.8887409606828927,\n",
       " 'exclude': 2.5877109650189114,\n",
       " 'excuse': 2.5877109650189114,\n",
       " 'exert': 2.110589710299249,\n",
       " 'exhaust': 1.6334684555795864,\n",
       " 'exhausting': 2.5877109650189114,\n",
       " 'exist': 1.0314084642516241,\n",
       " 'existence': 1.7426129250046545,\n",
       " 'exit': 1.6846209780269679,\n",
       " 'expand': 2.28668096935493,\n",
       " 'expansion': 1.265491670284992,\n",
       " 'expect': 1.6846209780269679,\n",
       " 'experience': 1.7426129250046545,\n",
       " 'experiment': 0.964461674621011,\n",
       " 'experimental': 0.6383209583739986,\n",
       " 'experimentally': 1.5463182798606863,\n",
       " 'explain': 1.7426129250046545,\n",
       " 'explanation': 1.9856509736909491,\n",
       " 'explicit': 1.8095597146352678,\n",
       " 'explicitly': 2.110589710299249,\n",
       " 'exploratory': 2.5877109650189114,\n",
       " 'explore': 2.5877109650189114,\n",
       " 'exponent': 2.28668096935493,\n",
       " 'exponential': 1.8887409606828927,\n",
       " 'exponentially': 2.28668096935493,\n",
       " 'expose': 1.8887409606828927,\n",
       " 'exposition': 2.5877109650189114,\n",
       " 'expound': 2.5877109650189114,\n",
       " 'express': 1.6334684555795864,\n",
       " 'expression': 1.3572620436406375,\n",
       " 'extend': 1.2259831290013186,\n",
       " 'extension': 1.3835909823629866,\n",
       " 'extensional': 2.5877109650189114,\n",
       " 'extensive': 1.7426129250046545,\n",
       " 'extensively': 2.110589710299249,\n",
       " 'extent': 1.6846209780269679,\n",
       " 'exterior': 2.28668096935493,\n",
       " ...}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc752dd0",
   "metadata": {},
   "source": [
    "#### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "31f34497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a temporary dataframe\n",
    "temp_doc= documents[['docid', 'tokens']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7149c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting sum of IDF values for a query-document pair\n",
    "def idf_sum(dtokens, qtokens):\n",
    "    #getting common terms in query and document\n",
    "    common_term= set(dtokens).intersection(set(qtokens))\n",
    "    \n",
    "    #Getting IDF values for common terms\n",
    "    idf_list=[value for key, value in idf_dict.items() if key in common_term]\n",
    "    \n",
    "    return sum(idf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2fbd8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_rank(qtokens):\n",
    "  # Getting sum of IDF values for all the quer-document pairs\n",
    "  temp_doc['idf_sum']=temp_doc['tokens'].apply(lambda x: idf_sum(x,qtokens))\n",
    "\n",
    "  # Sorting dataframe according to sum of IDF and getting relevant docs\n",
    "  rel_docs=temp_doc.sort_values(by='idf_sum',ascending=False).head()['docid'].values\n",
    "\n",
    "  return rel_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "06a0d740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard_rel</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>jaccard_ap</th>\n",
       "      <th>tf_rel</th>\n",
       "      <th>tf_ap</th>\n",
       "      <th>idf_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "      <td>[similarity, law, obey, construct, aeroelastic...</td>\n",
       "      <td>[12, 51, 378, 670, 875]</td>\n",
       "      <td>[184, 29, 31, 57, 378]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[51, 12, 184, 364, 572]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[184, 51, 12, 625, 332]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "      <td>[structural, aeroelastic, problem, associate, ...</td>\n",
       "      <td>[12, 51, 700, 746, 875]</td>\n",
       "      <td>[12, 746, 15, 184, 858]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[12, 172, 51, 746, 798]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[12, 172, 51, 746, 364]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "      <td>[problem, heat, conduction, composite, slab, s...</td>\n",
       "      <td>[5, 584, 6, 145, 582]</td>\n",
       "      <td>[5, 6, 90, 91, 119]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[5, 980, 584, 91, 395]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[5, 91, 625, 584, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "      <td>[method, dash, exact, approximate, dash, prese...</td>\n",
       "      <td>[122, 1306, 639, 655, 988]</td>\n",
       "      <td>[48, 122, 354, 360, 1005]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[122, 234, 1104, 924, 1307]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[122, 556, 1104, 234, 924]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "      <td>[real, gas, transport, property, air, availabl...</td>\n",
       "      <td>[405, 302, 436, 583, 616]</td>\n",
       "      <td>[259, 405, 302, 436, 437]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[302, 185, 616, 1009, 1313]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[302, 332, 405, 1009, 583]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0    1  what similarity laws must be obeyed when const...   \n",
       "1    2  what are the structural and aeroelastic proble...   \n",
       "2    3  what problems of heat conduction in composite ...   \n",
       "3    8  what methods -dash exact or approximate -dash ...   \n",
       "4   10  are real-gas transport properties for air avai...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [similarity, law, obey, construct, aeroelastic...   \n",
       "1  [structural, aeroelastic, problem, associate, ...   \n",
       "2  [problem, heat, conduction, composite, slab, s...   \n",
       "3  [method, dash, exact, approximate, dash, prese...   \n",
       "4  [real, gas, transport, property, air, availabl...   \n",
       "\n",
       "                  jaccard_rel               ground_truth  jaccard_ap  \\\n",
       "0     [12, 51, 378, 670, 875]     [184, 29, 31, 57, 378]    0.333333   \n",
       "1     [12, 51, 700, 746, 875]    [12, 746, 15, 184, 858]    0.750000   \n",
       "2       [5, 584, 6, 145, 582]        [5, 6, 90, 91, 119]    0.833333   \n",
       "3  [122, 1306, 639, 655, 988]  [48, 122, 354, 360, 1005]    1.000000   \n",
       "4   [405, 302, 436, 583, 616]  [259, 405, 302, 436, 437]    1.000000   \n",
       "\n",
       "                        tf_rel     tf_ap                     idf_rel  \n",
       "0      [51, 12, 184, 364, 572]  0.333333     [184, 51, 12, 625, 332]  \n",
       "1      [12, 172, 51, 746, 798]  0.750000     [12, 172, 51, 746, 364]  \n",
       "2       [5, 980, 584, 91, 395]  0.750000       [5, 91, 625, 584, 90]  \n",
       "3  [122, 234, 1104, 924, 1307]  1.000000  [122, 556, 1104, 234, 924]  \n",
       "4  [302, 185, 616, 1009, 1313]  1.000000  [302, 332, 405, 1009, 583]  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking documents according to inverse document frequency\n",
    "queries['idf_rel']=queries['tokens'].apply(lambda x: idf_rank(x))\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "691dac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision=> 0.64281045751634\n"
     ]
    }
   ],
   "source": [
    "#Evaluation on train set\n",
    "# Finding average precision for each query\n",
    "queries['idf_ap']=queries.apply(lambda x: average_precision(x['idf_rel'],x['ground_truth']),axis=1)\n",
    "\n",
    "# Finding Mean Average Precision\n",
    "print('Mean Average Precision=>',queries['idf_ap'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cbd5c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision on Validation Set=> 0.37626262626262624\n"
     ]
    }
   ],
   "source": [
    "#Evaluation on validation set\n",
    "\n",
    "# Ranking documents according to inverse document frequency\n",
    "queries_val['idf_rel']=queries_val['tokens'].apply(lambda x: idf_rank(x))\n",
    "\n",
    "# Finding average precision for each query\n",
    "queries_val['idf_ap']=queries_val.apply(lambda x: average_precision(x['idf_rel'],x['ground_truth']),axis=1)\n",
    "\n",
    "# Finding Mean Average Precision\n",
    "print('Mean Average Precision on Validation Set=>',queries_val['idf_ap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e924b",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d3f0b7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablate</th>\n",
       "      <th>ablating</th>\n",
       "      <th>ablation</th>\n",
       "      <th>able</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absence</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>z</th>\n",
       "      <th>zbrozek</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3042 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ab  abbreviate  ability  ablate  ablating  ablation  able  abrupt  \\\n",
       "0  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "1  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "2  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "3  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "4  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "\n",
       "   abruptly  absence  ...  year  yield  york  young    z  zbrozek  zero  \\\n",
       "0       0.0      0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0   \n",
       "1       0.0      0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0   \n",
       "2       0.0      0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0   \n",
       "3       0.0      0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0   \n",
       "4       0.0      0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0   \n",
       "\n",
       "   zeroth  zone  zuk  \n",
       "0     0.0   0.0  0.0  \n",
       "1     0.0   0.0  0.0  \n",
       "2     0.0   0.0  0.0  \n",
       "3     0.0   0.0  0.0  \n",
       "4     0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 3042 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating TF-IDF\n",
    "documents_tfidf= documents_tf.iloc[:,1:]* list(idf_dict.values())\n",
    "documents_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cd25090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (387, 3043)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablate</th>\n",
       "      <th>ablating</th>\n",
       "      <th>ablation</th>\n",
       "      <th>able</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>z</th>\n",
       "      <th>zbrozek</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3043 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid   ab  abbreviate  ability  ablate  ablating  ablation  able  abrupt  \\\n",
       "0      2  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "1      3  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "2      5  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "3      6  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "4     12  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "\n",
       "   abruptly  ...  year  yield  york  young    z  zbrozek  zero  zeroth  zone  \\\n",
       "0       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "1       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "2       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "3       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "4       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "\n",
       "   zuk  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 3043 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a column of docids\n",
    "documents_tfidf= pd.concat([documents[['docid']],documents_tfidf], axis=1)\n",
    "print('Shape :', documents_tfidf.shape)\n",
    "documents_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2eeb2a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'approximation': 0.9249531333373373,\n",
       " 'arise': 1.4415829293406734,\n",
       " 'body': 0.8179179714411188,\n",
       " 'boundary': 0.7825560609575196,\n",
       " 'classical': 1.5463182798606863,\n",
       " 'consequently': 2.110589710299249,\n",
       " 'consider': 1.0167952618775644,\n",
       " 'constant': 0.8887409606828927,\n",
       " 'curved': 1.6334684555795864,\n",
       " 'different': 1.1405529336766922,\n",
       " 'dimensional': 1.0532614720216564,\n",
       " 'discuss': 0.7243881048984555,\n",
       " 'discussion': 1.2074997233073055,\n",
       " 'edge': 0.7488618742816561,\n",
       " 'effect': 0.4323749275538496,\n",
       " 'emit': 2.5877109650189114,\n",
       " 'exist': 1.0314084642516241,\n",
       " 'feature': 1.3835909823629866,\n",
       " 'ferri': 2.28668096935493,\n",
       " 'flat': 1.1061597913506378,\n",
       " 'flow': 0.5293135804637596,\n",
       " 'fluid': 1.3741895767992272,\n",
       " 'free': 1.1444700154382332,\n",
       " 'high': 0.5964848893264165,\n",
       " 'hypersonic': 1.1024255232317401,\n",
       " 'incompressible': 1.311343739741794,\n",
       " 'instance': 1.8887409606828927,\n",
       " 'investigate': 1.0195092409519164,\n",
       " 'inviscid': 1.8692846438486488,\n",
       " 'irrotational': 1.9856509736909491,\n",
       " 'layer': 0.8049169630236986,\n",
       " 'leading': 1.9856509736909491,\n",
       " 'libby': 2.5877109650189114,\n",
       " 'necessary': 1.5085297189712865,\n",
       " 'nose': 1.189770956346874,\n",
       " 'novel': 2.5877109650189114,\n",
       " 'original': 1.7426129250046545,\n",
       " 'outside': 1.6334684555795864,\n",
       " 'paper': 0.8168589533767673,\n",
       " 'past': 1.9640985210160808,\n",
       " 'plate': 1.0193375574236028,\n",
       " 'possible': 1.0825609866990054,\n",
       " 'prandtls': 2.975040531644753,\n",
       " 'present': 0.4573771965239053,\n",
       " 'problem': 1.0464856341542437,\n",
       " 'recently': 1.3835909823629866,\n",
       " 'region': 0.9064697276433242,\n",
       " 'restrict': 1.8887409606828927,\n",
       " 'rotational': 2.2671916862628034,\n",
       " 'shear': 1.5044423937208438,\n",
       " 'shock': 0.9123085656068961,\n",
       " 'show': 0.5665216659489734,\n",
       " 'simple': 1.1024255232317401,\n",
       " 'situation': 2.5833914776913156,\n",
       " 'small': 0.9271786382179884,\n",
       " 'somewhat': 1.7426129250046545,\n",
       " 'speed': 0.6286695726978178,\n",
       " 'steady': 1.1253129671199553,\n",
       " 'stream': 1.0193375574236028,\n",
       " 'study': 1.0724168707792596,\n",
       " 'treat': 1.2866809693549301,\n",
       " 'usually': 1.6846209780269679,\n",
       " 'viscosity': 1.8000933697844401,\n",
       " 'viscous': 1.4263832875355595,\n",
       " 'vorticity': 1.9626424137321998,\n",
       " 'wave': 1.0439219180953565}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting TF-IDF values for the terms in the first document\n",
    "print(\"Document ID: \", documents_tfidf['docid'][0])\n",
    "documents_tfidf.loc[0,documents_tfidf.loc[0,:]!=0][1:].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8109b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking\n",
    "\n",
    "def tf_idf_rank(qtokens):\n",
    "  # Getting a list of unique query terms which are present in vocabulary\n",
    "  qtokens=list(set(qtokens).intersection(vocabulary))\n",
    "\n",
    "  # Creating list of columns to retrieve\n",
    "  columns=['docid']\n",
    "  columns.extend(qtokens)\n",
    "\n",
    "  # Retireving TF-IDF for query terms\n",
    "  temp_doc=documents_tfidf.loc[:,columns].copy()\n",
    "\n",
    "  # Adding all the frequencies\n",
    "  temp_doc['tfidf_sum']=temp_doc[qtokens].sum(axis=1)\n",
    "\n",
    "  # Sorting dataframe according to sum of TF-IDF and getting relevant docs\n",
    "  rel_docs=temp_doc.sort_values(by='tfidf_sum',ascending=False).head()['docid'].values\n",
    "\n",
    "  return rel_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8d94fcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>tokens</th>\n",
       "      <th>jaccard_rel</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>jaccard_ap</th>\n",
       "      <th>tf_rel</th>\n",
       "      <th>tf_ap</th>\n",
       "      <th>idf_rel</th>\n",
       "      <th>idf_ap</th>\n",
       "      <th>tf_idf_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "      <td>[similarity, law, obey, construct, aeroelastic...</td>\n",
       "      <td>[12, 51, 378, 670, 875]</td>\n",
       "      <td>[184, 29, 31, 57, 378]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[51, 12, 184, 364, 572]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[184, 51, 12, 625, 332]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[51, 184, 12, 332, 625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "      <td>[structural, aeroelastic, problem, associate, ...</td>\n",
       "      <td>[12, 51, 700, 746, 875]</td>\n",
       "      <td>[12, 746, 15, 184, 858]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[12, 172, 51, 746, 798]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[12, 172, 51, 746, 364]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[12, 51, 172, 746, 724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "      <td>[problem, heat, conduction, composite, slab, s...</td>\n",
       "      <td>[5, 584, 6, 145, 582]</td>\n",
       "      <td>[5, 6, 90, 91, 119]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[5, 980, 584, 91, 395]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[5, 91, 625, 584, 90]</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>[5, 91, 90, 584, 625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>what methods -dash exact or approximate -dash ...</td>\n",
       "      <td>[method, dash, exact, approximate, dash, prese...</td>\n",
       "      <td>[122, 1306, 639, 655, 988]</td>\n",
       "      <td>[48, 122, 354, 360, 1005]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[122, 234, 1104, 924, 1307]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[122, 556, 1104, 234, 924]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[122, 234, 1104, 556, 1307]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>are real-gas transport properties for air avai...</td>\n",
       "      <td>[real, gas, transport, property, air, availabl...</td>\n",
       "      <td>[405, 302, 436, 583, 616]</td>\n",
       "      <td>[259, 405, 302, 436, 437]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[302, 185, 616, 1009, 1313]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[302, 332, 405, 1009, 583]</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[302, 1009, 185, 583, 332]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query  \\\n",
       "0    1  what similarity laws must be obeyed when const...   \n",
       "1    2  what are the structural and aeroelastic proble...   \n",
       "2    3  what problems of heat conduction in composite ...   \n",
       "3    8  what methods -dash exact or approximate -dash ...   \n",
       "4   10  are real-gas transport properties for air avai...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [similarity, law, obey, construct, aeroelastic...   \n",
       "1  [structural, aeroelastic, problem, associate, ...   \n",
       "2  [problem, heat, conduction, composite, slab, s...   \n",
       "3  [method, dash, exact, approximate, dash, prese...   \n",
       "4  [real, gas, transport, property, air, availabl...   \n",
       "\n",
       "                  jaccard_rel               ground_truth  jaccard_ap  \\\n",
       "0     [12, 51, 378, 670, 875]     [184, 29, 31, 57, 378]    0.333333   \n",
       "1     [12, 51, 700, 746, 875]    [12, 746, 15, 184, 858]    0.750000   \n",
       "2       [5, 584, 6, 145, 582]        [5, 6, 90, 91, 119]    0.833333   \n",
       "3  [122, 1306, 639, 655, 988]  [48, 122, 354, 360, 1005]    1.000000   \n",
       "4   [405, 302, 436, 583, 616]  [259, 405, 302, 436, 437]    1.000000   \n",
       "\n",
       "                        tf_rel     tf_ap                     idf_rel  \\\n",
       "0      [51, 12, 184, 364, 572]  0.333333     [184, 51, 12, 625, 332]   \n",
       "1      [12, 172, 51, 746, 798]  0.750000     [12, 172, 51, 746, 364]   \n",
       "2       [5, 980, 584, 91, 395]  0.750000       [5, 91, 625, 584, 90]   \n",
       "3  [122, 234, 1104, 924, 1307]  1.000000  [122, 556, 1104, 234, 924]   \n",
       "4  [302, 185, 616, 1009, 1313]  1.000000  [302, 332, 405, 1009, 583]   \n",
       "\n",
       "     idf_ap                   tf_idf_rel  \n",
       "0  1.000000      [51, 184, 12, 332, 625]  \n",
       "1  0.750000      [12, 51, 172, 746, 724]  \n",
       "2  0.866667        [5, 91, 90, 584, 625]  \n",
       "3  1.000000  [122, 234, 1104, 556, 1307]  \n",
       "4  0.833333   [302, 1009, 185, 583, 332]  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries['tf_idf_rel']=queries['tokens'].apply(lambda x: tf_idf_rank(x))\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6c075b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision=> 0.659640522875817\n"
     ]
    }
   ],
   "source": [
    "#Evaluation on training set\n",
    "\n",
    "# Finding average precision for each query\n",
    "queries['tfidf_ap']=queries.apply(lambda x: average_precision(x['tf_idf_rel'],x['ground_truth']),axis=1)\n",
    "\n",
    "# Finding Mean Average Precision\n",
    "print('Mean Average Precision=>',queries['tfidf_ap'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3acd472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision on Validation Set=> 0.42941919191919187\n"
     ]
    }
   ],
   "source": [
    "#Evaluation on validation set\n",
    "\n",
    "# Ranking documents according to TF-IDF\n",
    "queries_val['tfidf_rel']=queries_val['tokens'].apply(lambda x: tf_idf_rank(x))\n",
    "\n",
    "# Finding average precision for each query\n",
    "queries_val['tfidf_ap']=queries_val.apply(lambda x: average_precision(x['tfidf_rel'],x['ground_truth']),axis=1)\n",
    "\n",
    "# Finding Mean Average Precision\n",
    "print('Mean Average Precision on Validation Set=>',queries_val['tfidf_ap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eab955",
   "metadata": {},
   "source": [
    "#### TF-IDF based vector space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b8404719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tfidf_queries(queries_data):\n",
    "  tf_list_queries=[]\n",
    "\n",
    "  # Getting Term frequencies\n",
    "  for tokens in queries_data['tokens']:\n",
    "    # Initliatizing a dictionary with 0 frequency\n",
    "    queries_dict=dict.fromkeys(vocabulary,0)      \n",
    "    # Counting term frequencies\n",
    "    for term in set(tokens).intersection(vocabulary):\n",
    "      queries_dict[term]+=1\n",
    "    # Adding dictionary to list\n",
    "    tf_list_queries.append(queries_dict)\n",
    "\n",
    "  # Creating a dataframe of term frequencies for queries\n",
    "  queries_tf=pd.DataFrame(tf_list_queries)\n",
    "\n",
    "  # Log Normalizing the term counts for queries\n",
    "  queries_tf=queries_tf.applymap(log_normalize)\n",
    "\n",
    "  # Calculating TF-IDF for queries\n",
    "  queries_tfidf=queries_tf*list(idf_dict.values())\n",
    "\n",
    "  # Adding a column of qids\n",
    "  queries_tfidf=pd.concat([queries_data['qid'],queries_tfidf],axis=1)\n",
    "\n",
    "  return queries_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5f4936aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (85, 3043)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablate</th>\n",
       "      <th>ablating</th>\n",
       "      <th>ablation</th>\n",
       "      <th>able</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>z</th>\n",
       "      <th>zbrozek</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3043 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid   ab  abbreviate  ability  ablate  ablating  ablation  able  abrupt  \\\n",
       "0    1  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "1    2  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "2    3  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "3    8  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "4   10  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "\n",
       "   abruptly  ...  year  yield  york  young    z  zbrozek  zero  zeroth  zone  \\\n",
       "0       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "1       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "2       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "3       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "4       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "\n",
       "   zuk  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 3043 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating TF-IDF vectors for queries in train set\n",
    "queries_tfidf=gen_tfidf_queries(queries)\n",
    "print('Shape :',queries_tfidf.shape)\n",
    "queries_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dc5b17f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (22, 3043)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablate</th>\n",
       "      <th>ablating</th>\n",
       "      <th>ablation</th>\n",
       "      <th>able</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>z</th>\n",
       "      <th>zbrozek</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3043 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid   ab  abbreviate  ability  ablate  ablating  ablation  able  abrupt  \\\n",
       "0  189  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "1  190  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "2  191  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "3  194  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "4  196  0.0         0.0      0.0     0.0       0.0       0.0   0.0     0.0   \n",
       "\n",
       "   abruptly  ...  year  yield  york  young    z  zbrozek  zero  zeroth  zone  \\\n",
       "0       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "1       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "2       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "3       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "4       0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0   0.0     0.0   0.0   \n",
       "\n",
       "   zuk  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 3043 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating TF-IDF vectors for queries in validation set\n",
    "queries_val_tfidf=gen_tfidf_queries(queries_val)\n",
    "print('Shape :',queries_val_tfidf.shape)\n",
    "queries_val_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cfc570d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking\n",
    "\n",
    "#temporary dataframe with tfidf values\n",
    "temp_doc_tfidf= documents_tfidf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "919b93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2d4ab2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_tfidf.iloc[0,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "215f5799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_doc_tfidf.iloc[0,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0b5de950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01570257]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cosine similarity takes the vectors as nested arrays\n",
    "\n",
    "cosine_similarity(queries_tfidf.iloc[0,1:].values.reshape(1,-1),temp_doc_tfidf.iloc[0,1:].values.reshape(1,-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c959b23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015702570044666825"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(queries_tfidf.iloc[0,1:].values.reshape(1,-1),temp_doc_tfidf.iloc[0,1:].values.reshape(1,-1) ).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "81d35afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vsm_rank(queries_data):\n",
    "  # Finding cosine similarity score for every document vector against a query vector\n",
    "  temp_doc_tfidf['tfidf_vsm']=temp_doc_tfidf.apply(lambda x: cosine_similarity(x.values[1:].reshape(1, -1),queries_data[1:].values.reshape(1, -1)).item(),axis=1)\n",
    "  \n",
    "  # Sorting dataframe according to sum of cosine similarity score and getting relevant docs\n",
    "  rel_docs=temp_doc_tfidf.sort_values(by='tfidf_vsm',ascending=False).head()['docid'].values\n",
    "\n",
    "  # Droppping similarity column\n",
    "  temp_doc_tfidf.drop(columns='tfidf_vsm',inplace=True)\n",
    "\n",
    "  return rel_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9e28e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries['tfidf_vsm_rel']= queries_tfidf.apply(lambda x: tfidf_vsm_rank(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e4f58490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision on train set : 0.6595261437908496\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on train set\n",
    "\n",
    "# Finding average precision for each query\n",
    "queries['tfidf_vsm_ap']=queries.apply(lambda x: average_precision(x['tfidf_vsm_rel'],x['ground_truth']),axis=1)\n",
    "\n",
    "# Finding Mean Average Precision\n",
    "print('Mean Average Precision on train set :',queries['tfidf_vsm_ap'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ed8fc626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision on validation set : 0.3535353535353535\n"
     ]
    }
   ],
   "source": [
    "# Ranking documents according to Cosine Similarity\n",
    "queries_val['tfidf_vsm_rel']=queries_val_tfidf.apply(lambda x: tfidf_vsm_rank(x),axis=1)\n",
    "\n",
    "# Finding average precision for each query\n",
    "queries_val['tfidf_vsm_ap']=queries_val.apply(lambda x: average_precision(x['tfidf_vsm_rel'],x['ground_truth']),axis=1)\n",
    "\n",
    "# Finding Mean Average Precision\n",
    "print('Mean Average Precision on validation set :',queries_val['tfidf_vsm_ap'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf7df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
